{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67561337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70fab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/all_universe_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Mark each prediction as ambiguous\n",
    "#df['is_ambiguous'] = df['pred_set'].apply(lambda labels: 1 if len(labels) > 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e98a4",
   "metadata": {},
   "source": [
    "for CP threshold policy no difference, is it double in this data frame? Could this cause problems with fanova?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a795fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df['pred_set'] = df['pred_set'].apply(\n",
    "    lambda x: literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "df['is_ambiguous'] = df['pred_set'].apply(lambda preds: 1 if len(preds) > 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5456d2c",
   "metadata": {},
   "source": [
    "# Melt the subgroup flags into one column so you can group by them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f44fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of binary subgroup columns\n",
    "subgroup_cols = ['frau1', 'nongerman', 'nongerman_male', 'nongerman_female']\n",
    "\n",
    "# Melt to long format: one row per (row, subgroup) where value == 1\n",
    "df_long = df.melt(\n",
    "    id_vars=['UniverseID', 'feature_set', 'model', 'is_ambiguous'], #'threshold_policy'\n",
    "    value_vars=subgroup_cols,\n",
    "    var_name='subgroup',\n",
    "    value_name='is_member'\n",
    ")\n",
    "\n",
    "# Filter to keep only the subgroup memberships (i.e., rows where the person is in that group)\n",
    "df_long = df_long[df_long['is_member'] == 1]\n",
    "\n",
    "# in subgroup column it says \"other 9%\", for what does it stand? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f452b",
   "metadata": {},
   "source": [
    "# Compute the fraction of ambiguous predictions per (universe, subgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1fc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['UniverseID', 'feature_set', 'model', 'subgroup'] #'threshold_policy',\n",
    "fractions = df_long.groupby(group_cols)['is_ambiguous'].mean().reset_index()\n",
    "fractions.rename(columns={'is_ambiguous': 'ambiguity_fraction'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6276f69",
   "metadata": {},
   "source": [
    "ToDo: fractions has 12 universes, but only 6 are actually different because of CP\n",
    "- Do I need to include overall in subgroups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597cf19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows where UniverseID is an odd number\n",
    "unique_universes = fractions[fractions['UniverseID'] % 2 == 1].reset_index(drop=True)\n",
    "fractions = unique_universes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a67c1",
   "metadata": {},
   "source": [
    "# For each universe, compute the maximum pairwise difference in ambiguity fraction between subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c158d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute disparity per universe = max - min ambiguity_fraction across subgroups\n",
    "disparity_df = fractions.groupby(['feature_set', 'model'])['ambiguity_fraction']\\\n",
    "                        .agg(lambda x: x.max() - x.min())\\\n",
    "                        .reset_index(name='ambiguity_disparity')\n",
    "\n",
    "## add universe id \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cefae4",
   "metadata": {},
   "source": [
    "# fANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61602ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ConfigSpace import ConfigurationSpace, CategoricalHyperparameter\n",
    "from fanova import fANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6201a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ConfigSpace with categorical decision options\n",
    "cs = ConfigurationSpace()\n",
    "for col in ['feature_set', 'model']: # 'threshold_policy'\n",
    "    choices = sorted(disparity_df[col].unique().tolist())\n",
    "    cs.add(CategoricalHyperparameter(col, choices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47736203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical values as integer codes\n",
    "#encoders = {\n",
    "#    col: {val: idx for idx, val in enumerate(sorted(disparity_df[col].unique()))}\n",
    "#    for col in ['feature_set', 'model', 'threshold_policy']\n",
    "#}\n",
    "#\n",
    "#X = np.vstack([\n",
    "#    disparity_df['feature_set'].map(encoders['feature_set']),\n",
    "#    disparity_df['model'].map(encoders['model']),\n",
    "#    disparity_df['threshold_policy'].map(encoders['threshold_policy']),\n",
    "#]).T\n",
    "#\n",
    "#Y = disparity_df['ambiguity_disparity'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7395085",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_order = [hp.name for hp in cs.values()]\n",
    "X = disparity_df[hp_order].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map categorical values to integers (same as before)\n",
    "for col in hp_order:\n",
    "    encoder = {val: i for i, val in enumerate(sorted(disparity_df[col].unique()))}\n",
    "    X[col] = X[col].map(encoder)\n",
    "\n",
    "X_array = X.to_numpy(dtype=float)  # ensure float dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1502d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = disparity_df['ambiguity_disparity'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e20044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fANOVA\n",
    "fanova = fANOVA(X_array, Y, config_space=cs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get individual importance scores\n",
    "importance = {\n",
    "    'feature_set': fanova.quantify_importance((0,))['individual importance'],\n",
    "    'model': fanova.quantify_importance((1,))['individual importance'],\n",
    "    #'threshold_policy': fanova.quantify_importance((2,))['individual importance'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd082411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get individual importance scores\n",
    "# Check for valid dimension indices and handle empty or invalid results\n",
    "try:\n",
    "    importance = {\n",
    "        'feature_set': fanova.quantify_importance((0,))['individual importance'],\n",
    "        'model': fanova.quantify_importance((1,))['individual importance'],\n",
    "        # 'threshold_policy': fanova.quantify_importance((2,))['individual importance'],\n",
    "    }\n",
    "except (IndexError, KeyError, RuntimeError) as e:\n",
    "    print(f\"Error computing importance: {e}\")\n",
    "    importance = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect which dimensions are available in fANOVA\n",
    "print(\"Available dimensions in V_U_total:\")\n",
    "print(list(fanova.V_U_total.keys()))\n",
    "\n",
    "print(\"Total variance per tree (non-zero indices):\")\n",
    "print([i for i, v in enumerate(fanova.trees_total_variance) if v != 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1488ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get individual importance scores with debug output\n",
    "try:\n",
    "    print(\"Available dimensions in V_U_total:\", list(fanova.V_U_total.keys()))\n",
    "    print(\"Non-zero total variances:\", [i for i, v in enumerate(fanova.trees_total_variance) if v != 0])\n",
    "\n",
    "    importance = {\n",
    "        'feature_set': fanova.quantify_importance((0,))['individual importance'],\n",
    "        'model': fanova.quantify_importance((1,))['individual importance'],\n",
    "    }\n",
    "except (IndexError, KeyError, RuntimeError) as e:\n",
    "    print(f\"Error computing importance: {e}\")\n",
    "    importance = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9696b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep inspection of V_U_total and trees_total_variance\n",
    "sub_dims = (0,)\n",
    "try:\n",
    "    print(f\"Length V_U_total{sub_dims} =\", len(fanova.V_U_total[sub_dims]))\n",
    "    print(f\"Length trees_total_variance =\", len(fanova.trees_total_variance))\n",
    "\n",
    "    for i in range(len(fanova.V_U_total[sub_dims])):\n",
    "        print(f\"Tree {i}: V_U_total = {fanova.V_U_total[sub_dims][i]}, Total variance = {fanova.trees_total_variance[i]}\")\n",
    "\n",
    "    # Try quantifying importance\n",
    "    importance = fanova.quantify_importance(sub_dims)['individual importance']\n",
    "    print(\"Importance computed:\", importance)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Exception during inspection or importance computation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b114096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for valid variance data before computing importance\n",
    "sub_dims = (0,)\n",
    "\n",
    "if sub_dims in fanova.V_U_total and len(fanova.V_U_total[sub_dims]) > 0:\n",
    "    try:\n",
    "        importance = fanova.quantify_importance(sub_dims)['individual importance']\n",
    "        print(\"Importance computed:\", importance)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception during importance computation: {e}\")\n",
    "        importance = None\n",
    "else:\n",
    "    print(f\"No usable variance data for dimension {sub_dims}. Skipping.\")\n",
    "    importance = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b35618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safely compute importance for all expected dimensions\n",
    "importance = {}\n",
    "for i, name in enumerate(['feature_set', 'model']):\n",
    "    sub_dims = (i,)\n",
    "    if sub_dims in fanova.V_U_total and len(fanova.V_U_total[sub_dims]) > 0:\n",
    "        try:\n",
    "            imp = fanova.quantify_importance(sub_dims)['individual importance']\n",
    "            importance[name] = imp\n",
    "            print(f\"Importance for {name}: {imp}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Exception during importance computation for {name}: {e}\")\n",
    "            importance[name] = None\n",
    "    else:\n",
    "        print(f\"No usable variance data for dimension {sub_dims} ({name}). Skipping.\")\n",
    "        importance[name] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab7c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate full contents of V_U_total and trees_total_variance\n",
    "print(\"All entries in V_U_total:\")\n",
    "for dims, values in fanova.V_U_total.items():\n",
    "    print(f\"  {dims}: length = {len(values)}\")\n",
    "\n",
    "print(\"Total number of trees with non-zero variance:\", sum(v != 0 for v in fanova.trees_total_variance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade6dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect raw input variance to understand why fANOVA produced no usable importance values\n",
    "\n",
    "# X should be the input matrix passed to fANOVA\n",
    "variances = np.var(X, axis=0)\n",
    "for i, v in enumerate(variances):\n",
    "    print(f\"Feature {i}: variance = {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ed03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available attributes\n",
    "print(\"Available attributes in fanova:\", dir(fanova))\n",
    "\n",
    "# Fallback if `n_dimensions` is not available\n",
    "if hasattr(fanova, 'config_space'):\n",
    "    print(\"Config space dimensions:\", len(fanova.config_space.get_hyperparameters()))\n",
    "\n",
    "# Attempt recomputation (alternative safe method)\n",
    "try:\n",
    "    fanova._compute_variances()  # Internal method that populates V_U_total\n",
    "    print(\"Recomputation of variances triggered.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during variance recomputation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127817c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try inspecting trees from the_forest assuming it's an object with accessible attribute\n",
    "try:\n",
    "    trees = fanova.the_forest.trees\n",
    "    print(f\"Number of trees in the forest: {len(trees)}\")\n",
    "    for i, tree in enumerate(trees[:3]):\n",
    "        print(f\"Tree {i} type: {type(tree)}\")\n",
    "        print(f\"Tree {i} attributes: {dir(tree)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inspecting trees in the forest: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use safe access method to probe attributes\n",
    "from inspect import getmembers\n",
    "\n",
    "# Try accessing all non-method members safely\n",
    "try:\n",
    "    members = getmembers(fanova.the_forest, lambda a: not callable(a))\n",
    "    for name, value in members:\n",
    "        if not name.startswith('__'):\n",
    "            if isinstance(value, list):\n",
    "                print(f\"{name}: list of length {len(value)}\")\n",
    "            elif hasattr(value, '__len__'):\n",
    "                print(f\"{name}: len = {len(value)}\")\n",
    "            else:\n",
    "                print(f\"{name}: type = {type(value)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while accessing members of fanova.the_forest: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8cbf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually try to access attributes that may hold the trees\n",
    "possible_attrs = [\n",
    "    'rf', 'forest', '_forest', 'estimators_', 'base_forest', 'wrapped_forest', 'model_forest', 'raw_forest'\n",
    "]\n",
    "\n",
    "for attr in possible_attrs:\n",
    "    try:\n",
    "        value = getattr(fanova.the_forest, attr)\n",
    "        print(f\"{attr}: type={type(value)}, len={len(value) if hasattr(value, '__len__') else 'N/A'}\")\n",
    "    except AttributeError:\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"{attr}: error accessing attribute: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7c8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the string representation of the forest object to look for clues\n",
    "print(\"fanova.the_forest representation:\")\n",
    "print(fanova.the_forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12442da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try accessing pyrfr wrapper if available\n",
    "try:\n",
    "    import pyrfr\n",
    "    if isinstance(fanova.the_forest, pyrfr.regression.fanova_forest):\n",
    "        print(\"Confirmed: fanova.the_forest is a pyrfr fanova_forest instance.\")\n",
    "        print(\"Number of trees:\", fanova.the_forest.num_trees())\n",
    "        print(\"Number of dimensions:\", fanova.the_forest.num_features())\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing pyrfr forest methods: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229813f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"fANOVA results (variance explained in ambiguity disparity):\")\n",
    "for key, val in importance.items():\n",
    "    print(f\"  {key}: {val * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0221b07d",
   "metadata": {},
   "source": [
    "# fANOVA v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766027a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "if not hasattr(np, 'float'):\n",
    "    np.float = float  # Patch for fanova compatibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a33d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build ConfigSpace and add hyperparameters\n",
    "from ConfigSpace import ConfigurationSpace, CategoricalHyperparameter\n",
    "\n",
    "cs = ConfigurationSpace()\n",
    "cs.add(\n",
    "    CategoricalHyperparameter(\"feature_set\", sorted(disparity_df[\"feature_set\"].unique())),\n",
    "    CategoricalHyperparameter(\"model\", sorted(disparity_df[\"model\"].unique())),\n",
    "    #CategoricalHyperparameter(\"threshold_policy\", sorted(disparity_df[\"threshold_policy\"].unique()))\n",
    ")\n",
    "\n",
    "# Step 2: Get correct hyperparameter order\n",
    "hp_order = [hp.name for hp in list(cs.values())]\n",
    "\n",
    "# Step 3: Encode categorical variables using consistent mapping\n",
    "X_df = disparity_df[hp_order].copy()\n",
    "for col in hp_order:\n",
    "    encoder = {val: i for i, val in enumerate(sorted(X_df[col].unique()))}\n",
    "    X_df[col] = X_df[col].map(encoder)\n",
    "X_df = X_df.astype(float)\n",
    "\n",
    "# Step 4: Now pass this labeled DataFrame directly to fANOVA\n",
    "from fanova import fANOVA\n",
    "\n",
    "Y = disparity_df[\"ambiguity_disparity\"].to_numpy()\n",
    "fanova = fANOVA(X_df, Y, config_space=cs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract hyperparameters in correct order (no deprecated method)\n",
    "hp_list = list(cs.values())\n",
    "\n",
    "importance_scores = {}\n",
    "\n",
    "# Step 2: Loop through in order and extract individual importance scores\n",
    "for i, hp in enumerate(hp_list):\n",
    "    try:\n",
    "        result = fanova.quantify_importance((i,))\n",
    "        importance_scores[hp.name] = result[\"individual importance\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Could not compute importance for {hp.name}: {e}\")\n",
    "\n",
    "# Step 3: Format and display\n",
    "importance_df = pd.DataFrame.from_dict(\n",
    "    importance_scores, orient=\"index\", columns=[\"individual importance\"]\n",
    ")\n",
    "importance_df.sort_values(\"individual importance\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"fANOVA: Individual variance explained per decision factor (%):\")\n",
    "print((importance_df * 100).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fe21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(\"Var(Y):\", np.var(Y))\n",
    "# extremly small variance, so not much to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4bb747",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape:\", X_df.shape)\n",
    "print(\"Unique values per column:\")\n",
    "print(X_df.nunique())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
