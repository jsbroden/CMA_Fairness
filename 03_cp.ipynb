{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07550eba",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad59357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julia/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/Users/julia/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "\n",
    "from utils import (\n",
    "    compute_nc_scores,\n",
    "    find_threshold,\n",
    "    predict_conformal_sets,\n",
    "    evaluate_sets,\n",
    "    summarize_by_indicator,\n",
    "    summarize_for_predicate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16090e24",
   "metadata": {},
   "source": [
    "## Data and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c8eccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_calib_f = pd.read_csv(\"./output/X_calib_f.csv\") # 2015, w. protected attributes\n",
    "#X_calib_s = pd.read_csv(\"./output/X_calib_s.csv\") # 2015, w/o protected attributes\n",
    "y_calib = pd.read_csv(\"./output/y_calib.csv\").iloc[:,0]\n",
    "\n",
    "X_test_f = pd.read_csv(\"./output/X_test_f.csv\")\n",
    "#X_test_s = pd.read_csv(\"./output/X_test_s.csv\")\n",
    "y_test = pd.read_csv(\"./output/y_test.csv\").iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84eb551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_test = pd.read_csv(\"./output/preds_test.csv\")\n",
    "\n",
    "glm1 = load(\"./models/glm1.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fbfe25",
   "metadata": {},
   "source": [
    "## Conformal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "102e8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscoverage level\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdce0aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_hat: 0.6604\n"
     ]
    }
   ],
   "source": [
    "probs_calib = glm1.predict_proba(X_calib_f)\n",
    "\n",
    "nc_scores = compute_nc_scores(probs_calib, y_calib)\n",
    "\n",
    "q_hat = find_threshold(nc_scores, alpha) # q_hat is data-driven threshold for classification\n",
    "print(f\"q_hat: {q_hat:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8be08fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With test data\n",
    "pred_sets = predict_conformal_sets(glm1, X_test_f, q_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2342aaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.91\n",
      "Avg. set size: 1.13\n"
     ]
    }
   ],
   "source": [
    "# With test data\n",
    "evaluation = evaluate_sets(pred_sets, y_test)\n",
    "print(f\"Coverage: {evaluation['coverage']:.2f}\")\n",
    "print(f\"Avg. set size: {evaluation['avg_size']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244cff0",
   "metadata": {},
   "source": [
    "## Analyzing CP per group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60c576df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cp_groups with the same index as X_test_f (and y_test)\n",
    "cp_groups = pd.DataFrame(index=X_test_f.index)\n",
    "cp_groups['pred_set'] = pd.Series(pred_sets, index=X_test_f.index).apply(lambda s: {int(x) for x in s})\n",
    "cp_groups['true_label'] = y_test.reindex(X_test_f.index)\n",
    "cp_groups['frau1'] = X_test_f['frau1']\n",
    "\n",
    "cp_groups['nongerman'] = np.where(\n",
    "    X_test_f['maxdeutsch1'] == 0, \n",
    "    1, \n",
    "    0\n",
    ")\n",
    "cp_groups.loc[\n",
    "    X_test_f['maxdeutsch.Missing.'] == 1, \n",
    "    'nongerman'\n",
    "] = np.nan\n",
    "\n",
    "cp_groups['nongerman_male'] = np.where(\n",
    "    (cp_groups['nongerman'] == 1) & (cp_groups['frau1'] == 0),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "cp_groups['nongerman_female'] = np.where(\n",
    "    (cp_groups['nongerman'] == 1) & (cp_groups['frau1'] == 1),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "cp_groups = cp_groups.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc757c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Coverage  Avg Set Size  Num Samples\n",
      "Group                                                \n",
      "frau1             0.909314      1.139507        37095\n",
      "nongerman         0.912929      1.075731        17813\n",
      "nongerman_male    0.928848      1.054400        11103\n",
      "nongerman_female  0.886587      1.111028         6710\n"
     ]
    }
   ],
   "source": [
    "# Conditional coverage and set size\n",
    "\n",
    "# List of subgroup indicators to evaluate\n",
    "groups = ['frau1', 'nongerman', 'nongerman_male', 'nongerman_female']\n",
    "\n",
    "# Align pred_sets with y_test indices for easy filtering\n",
    "pred_sets_series = pd.Series(pred_sets, index=y_test.index)\n",
    "\n",
    "# Prepare a list to collect results\n",
    "results = []\n",
    "\n",
    "for group in groups:\n",
    "    # Create a boolean mask for the current subgroup (True for indices in the subgroup)\n",
    "    mask = (cp_groups[group] == 1)\n",
    "    # Align the mask to y_test index (in case cp_groups has a subset of test indices)\n",
    "    mask_aligned = mask.reindex(y_test.index, fill_value=False)\n",
    "    \n",
    "    # Filter true labels and prediction sets for this subgroup\n",
    "    group_y = y_test[mask_aligned]             # true labels for this subgroup\n",
    "    group_pred_sets = pred_sets_series[mask_aligned]  # prediction sets for this subgroup\n",
    "    \n",
    "    # Compute coverage: fraction of cases where true label is in the prediction set\n",
    "    coverage = np.mean([\n",
    "        1 if true_label in pred_set else 0 \n",
    "        for true_label, pred_set in zip(group_y, group_pred_sets)\n",
    "    ])\n",
    "    # Compute average prediction set size for this subgroup\n",
    "    avg_set_size = np.mean([len(pred_set) for pred_set in group_pred_sets])\n",
    "    \n",
    "    # Store the results (optionally multiply coverage by 100 if you want percentage)\n",
    "    results.append({\n",
    "        'Group': group,\n",
    "        'Coverage': coverage,\n",
    "        'Avg Set Size': avg_set_size,\n",
    "        'Num Samples': mask_aligned.sum()  # number of test samples in this subgroup\n",
    "    })\n",
    "\n",
    "# Create a DataFrame for clear tabular display of the results\n",
    "coverage_results = pd.DataFrame(results).set_index('Group')\n",
    "print(coverage_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fedec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall true_label distribution:\n",
      "true_label\n",
      "0    75876\n",
      "1    11107\n",
      "Name: count, dtype: int64\n",
      "As proportions:\n",
      "true_label\n",
      "0    0.872308\n",
      "1    0.127692\n",
      "Name: proportion, dtype: float64\n",
      "P(true_label=1): 0.1277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subgroups true class label distributions\n",
    "\n",
    "# Overall distribution of true_label\n",
    "print(\"Overall true_label distribution:\")\n",
    "print(cp_groups['true_label'].value_counts().sort_index())\n",
    "print(\"As proportions:\")\n",
    "print(cp_groups['true_label'].value_counts(normalize=True).sort_index())\n",
    "print(f\"P(true_label=1): {cp_groups['true_label'].mean():.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "428b7adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution conditional on frau1:\n",
      "P(true_label=1 | frau1=0): 0.1235 (n=49888)\n",
      "P(true_label=1 | frau1=1): 0.1334 (n=37095)\n",
      "\n",
      "Total observations: 86983 (female: n=37095, male: n=49888)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution conditional on frau1\n",
    "print(\"Distribution conditional on frau1:\")\n",
    "for frau_val in [0, 1]:\n",
    "    subset = cp_groups[cp_groups['frau1'] == frau_val] # Get all females\n",
    "    prop_positive = subset['true_label'].mean() # What % of females have true_label=1?\n",
    "    print(f\"P(true_label=1 | frau1={frau_val}): {prop_positive:.4f} (n={len(subset)})\")\n",
    "print()\n",
    "\n",
    "# Add total counts\n",
    "n_female = (cp_groups['frau1'] == 1).sum()\n",
    "n_male = (cp_groups['frau1'] == 0).sum()\n",
    "print(f\"Total observations: {len(cp_groups)} (female: n={n_female}, male: n={n_male})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dce790ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution conditional on nongerman:\n",
      "P(true_label=1 | nongerman=0): 0.1321 (n=69170)\n",
      "P(true_label=1 | nongerman=1): 0.1104 (n=17813)\n",
      "\n",
      "Total observations: 86983 (german: n=69170, nongerman: n=17813)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution conditional on nongerman\n",
    "print(\"Distribution conditional on nongerman:\")\n",
    "for ng_val in [0, 1]:\n",
    "    subset = cp_groups[cp_groups['nongerman'] == ng_val]\n",
    "    prop_positive = subset['true_label'].mean()\n",
    "    print(f\"P(true_label=1 | nongerman={ng_val}): {prop_positive:.4f} (n={len(subset)})\")\n",
    "print()\n",
    "\n",
    "# Add total counts\n",
    "n_german = (cp_groups['nongerman'] == 0).sum()\n",
    "n_nongerman = (cp_groups['nongerman'] == 1).sum()\n",
    "print(f\"Total observations: {len(cp_groups)} (german: n={n_german}, nongerman: n={n_nongerman})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2e6c808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution conditional on nongerman subgroups:\n",
      "P(true_label=1 | nongerman_male=0): 0.1337 (n=75880)\n",
      "P(true_label=1 | nongerman_male=1): 0.0867 (n=11103)\n",
      "P(true_label=1 | nongerman_female=0): 0.1259 (n=80273)\n",
      "P(true_label=1 | nongerman_female=1): 0.1496 (n=6710)\n",
      "\n",
      "Total observations: 86983 (other: n=75880, nongerman male: n=11103)\n",
      "\n",
      "Total observations: 86983 (other: n=80273, nongerman female: n=6710)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution conditional on nongerman_male and nongerman_female\n",
    "print(\"Distribution conditional on nongerman subgroups:\")\n",
    "if 'nongerman_male' in cp_groups.columns:\n",
    "    for nm_val in [0, 1]:\n",
    "        subset = cp_groups[cp_groups['nongerman_male'] == nm_val]\n",
    "        prop_positive = subset['true_label'].mean()\n",
    "        print(f\"P(true_label=1 | nongerman_male={nm_val}): {prop_positive:.4f} (n={len(subset)})\")\n",
    "\n",
    "if 'nongerman_female' in cp_groups.columns:\n",
    "    for nf_val in [0, 1]:\n",
    "        subset = cp_groups[cp_groups['nongerman_female'] == nf_val]\n",
    "        prop_positive = subset['true_label'].mean()\n",
    "        print(f\"P(true_label=1 | nongerman_female={nf_val}): {prop_positive:.4f} (n={len(subset)})\")\n",
    "print()\n",
    "\n",
    "# Add total counts\n",
    "n_german_male = (cp_groups['nongerman_male'] == 0).sum()\n",
    "n_nongerman_male = (cp_groups['nongerman_male'] == 1).sum()\n",
    "print(f\"Total observations: {len(cp_groups)} (other: n={n_german_male}, nongerman male: n={n_nongerman_male})\")\n",
    "print()\n",
    "\n",
    "# Add total counts\n",
    "n_german_female = (cp_groups['nongerman_female'] == 0).sum()\n",
    "n_nongerman_female = (cp_groups['nongerman_female'] == 1).sum()\n",
    "print(f\"Total observations: {len(cp_groups)} (other: n={n_german_female}, nongerman female: n={n_nongerman_female})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1eaa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts:\n",
      "pred_set\n",
      "{0}       75347\n",
      "{0, 1}    10840\n",
      "{1}         796\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportions:\n",
      "pred_set\n",
      "{0}       0.866227\n",
      "{0, 1}    0.124622\n",
      "{1}       0.009151\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Baselines CP\n",
    "\n",
    "print(\"Value counts:\")\n",
    "print(cp_groups['pred_set'].value_counts())\n",
    "print(\"\\nProportions:\")\n",
    "print(cp_groups['pred_set'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95d1062f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among cases where pred_set == {0}:\n",
      "  Proportion true_label == 1:        0.097\n",
      "  Proportion frau1 == 1:             0.420\n",
      "  Proportion nongerman == 1:         0.218\n",
      "  Proportion nongerman_male == 1:    0.139\n",
      "  Proportion nongerman_female == 1:  0.079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_for_predicate(\n",
    "    cp_groups,\n",
    "    predicate=lambda s: set(s) == {0},\n",
    "    description=\"== {0}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "513af460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among cases where pred_set == {1}:\n",
      "  Proportion true_label == 1:        0.433\n",
      "  Proportion frau1 == 1:             0.371\n",
      "  Proportion nongerman == 1:         0.092\n",
      "  Proportion nongerman_male == 1:    0.049\n",
      "  Proportion nongerman_female == 1:  0.043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_for_predicate(\n",
    "    cp_groups,\n",
    "    predicate=lambda s: set(s) == {1},\n",
    "    description=\"== {1}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f322fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among cases where pred_set == {0,1}:\n",
      "  Proportion true_label == 1:        0.319\n",
      "  Proportion frau1 == 1:             0.477\n",
      "  Proportion nongerman == 1:         0.124\n",
      "  Proportion nongerman_male == 1:    0.056\n",
      "  Proportion nongerman_female == 1:  0.069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_for_predicate(\n",
    "    cp_groups,\n",
    "    predicate=lambda s: set(s) == {0,1},\n",
    "    description=\"== {0,1}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d4da4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counts by gender:\n",
      "\n",
      "        is_ambiguous  is_zero_only  is_one_only\n",
      "frau1                                          \n",
      "male            5665         43722          501\n",
      "female          5175         31625          295\n",
      "\n",
      "Percentages by gender:\n",
      "\n",
      "        is_ambiguous  is_zero_only  is_one_only\n",
      "frau1                                          \n",
      "male       11.355436     87.640314     1.004250\n",
      "female     13.950667     85.254077     0.795255\n"
     ]
    }
   ],
   "source": [
    "# Summarize for frau1 == 1 (vs 0)\n",
    "counts_female, pct_female = summarize_by_indicator(\n",
    "    cp_groups,\n",
    "    indicator_col='frau1',\n",
    "    positive_label='female',\n",
    "    negative_label='male'\n",
    ")\n",
    "\n",
    "print(\"\\nCounts by gender:\\n\")\n",
    "print(counts_female)\n",
    "print(\"\\nPercentages by gender:\\n\")\n",
    "print(pct_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1533a7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by nationality (German vs non‐German):\n",
      "\n",
      "            is_ambiguous  is_zero_only  is_one_only\n",
      "nongerman                                          \n",
      "German              9491         58956          723\n",
      "non‐German          1349         16391           73\n",
      "\n",
      "Percentages by nationality:\n",
      "\n",
      "            is_ambiguous  is_zero_only  is_one_only\n",
      "nongerman                                          \n",
      "German         13.721266     85.233483     1.045251\n",
      "non‐German      7.573121     92.017066     0.409813\n"
     ]
    }
   ],
   "source": [
    "# Summarize for nongerman == 1 (vs 0)\n",
    "counts_ng, pct_ng = summarize_by_indicator(\n",
    "    cp_groups,\n",
    "    indicator_col='nongerman',\n",
    "    positive_label='non‐German',\n",
    "    negative_label='German'\n",
    ")\n",
    "\n",
    "print(\"Counts by nationality (German vs non‐German):\\n\")\n",
    "print(counts_ng)\n",
    "print(\"\\nPercentages by nationality:\\n\")\n",
    "print(pct_ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57ea6ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counts for non‐German Male vs Others:\n",
      "\n",
      "                 is_ambiguous  is_zero_only  is_one_only\n",
      "nongerman_male                                          \n",
      "Others                  10236         64887          757\n",
      "non‐German Male           604         10460           39\n",
      "\n",
      "Percentages for non‐German Male vs Others:\n",
      "\n",
      "                 is_ambiguous  is_zero_only  is_one_only\n",
      "nongerman_male                                          \n",
      "Others              13.489721     85.512652     0.997628\n",
      "non‐German Male      5.439971     94.208772     0.351256\n"
     ]
    }
   ],
   "source": [
    "# Summarize for nongerman_male == 1 (vs 0)\n",
    "counts_ng_male, pct_ng_male = summarize_by_indicator(\n",
    "    cp_groups,\n",
    "    indicator_col='nongerman_male',\n",
    "    positive_label='non‐German Male',\n",
    "    negative_label='Others'\n",
    ")\n",
    "\n",
    "print(\"\\nCounts for non‐German Male vs Others:\\n\")\n",
    "print(counts_ng_male)\n",
    "print(\"\\nPercentages for non‐German Male vs Others:\\n\")\n",
    "print(pct_ng_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d7d5e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counts for non‐German Female vs Others:\n",
      "\n",
      "                   is_ambiguous  is_zero_only  is_one_only\n",
      "nongerman_female                                          \n",
      "Others                    10095         69416          762\n",
      "non‐German Female           745          5931           34\n",
      "\n",
      "Percentages for non‐German Female vs Others:\n",
      "\n",
      "                   is_ambiguous  is_zero_only  is_one_only\n",
      "nongerman_female                                          \n",
      "Others                12.575835     86.474904     0.949261\n",
      "non‐German Female     11.102832     88.390462     0.506706\n"
     ]
    }
   ],
   "source": [
    "# Summarize for nongerman_female == 1 (vs 0)\n",
    "counts_ng_female, pct_ng_female = summarize_by_indicator(\n",
    "    cp_groups,\n",
    "    indicator_col='nongerman_female',\n",
    "    positive_label='non‐German Female',\n",
    "    negative_label='Others'\n",
    ")\n",
    "\n",
    "print(\"\\nCounts for non‐German Female vs Others:\\n\")\n",
    "print(counts_ng_female)\n",
    "print(\"\\nPercentages for non‐German Female vs Others:\\n\")\n",
    "print(pct_ng_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7553ed",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9cbe613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (excluding ambiguous cases):\n",
      "[[70030   471]\n",
      " [ 7549   360]]\n",
      "Accuracy:  0.898\n",
      "Precision: 0.433\n",
      "Recall:    0.046\n",
      "F1 Score:  0.082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 1. Filter out ambiguous prediction sets (where pred_set == {0,1})\n",
    "confident_indices = [idx for idx, pset in enumerate(pred_sets) if pset != {0, 1}]\n",
    "\n",
    "# If there are no confident predictions, handle that case\n",
    "if len(confident_indices) == 0:\n",
    "    print(\"No confident predictions (all predictions were ambiguous). Confusion matrix cannot be computed.\")\n",
    "else:\n",
    "    # 2. Extract predicted labels from the remaining sets\n",
    "    y_pred_filtered = []\n",
    "    for idx in confident_indices:\n",
    "        pset = pred_sets[idx]\n",
    "        # pset can only be {0} or {1} here\n",
    "        predicted_label = 0 if pset == {0} else 1\n",
    "        y_pred_filtered.append(predicted_label)\n",
    "\n",
    "    # 3. Align predicted labels with the corresponding true labels\n",
    "    # Use the same indices to filter y_test\n",
    "    y_true_filtered = [y_test.iloc[idx] for idx in confident_indices]\n",
    "\n",
    "    # 4. Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true_filtered, y_pred_filtered)\n",
    "    print(\"Confusion matrix (excluding ambiguous cases):\")\n",
    "    print(cm)\n",
    "\n",
    "# Extract individual components\n",
    "TN, FP, FN, TP = cm.ravel()  # Unpacks the 2x2 matrix into values\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else float('nan')\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else float('nan')\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else float('nan')\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy:  {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1 Score:  {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "009dc272",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = cp_groups.index\n",
    "# Align arrays\n",
    "pred_sets_filtered = [pred_sets[i] for i in valid_idx]\n",
    "y_test_filtered = np.array(y_test)[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "693daaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Subgroup",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Coverage (non-ambiguous)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "be8ad26f-2b27-47b4-9ee6-6884f7f0b714",
       "rows": [
        [
         "frau1",
         "118.0",
         "28438.0",
         "177.0",
         "3187.0",
         "0.4",
         "0.0357034795763994",
         "0.06555555555555556",
         "0.36696825816538864"
        ],
        [
         "nongerman",
         "37.0",
         "14876.0",
         "36.0",
         "1515.0",
         "0.5068493150684932",
         "0.02384020618556701",
         "0.04553846153846154",
         "0.1892783647379373"
        ],
        [
         "nongerman_male",
         "22.0",
         "9687.0",
         "17.0",
         "773.0",
         "0.5641025641025641",
         "0.027672955974842768",
         "0.05275779376498801",
         "0.1207017463182461"
        ],
        [
         "nongerman_female",
         "15.0",
         "5189.0",
         "19.0",
         "742.0",
         "0.4411764705882353",
         "0.019815059445178335",
         "0.03792667509481669",
         "0.0685766184196912"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Coverage (non-ambiguous)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subgroup</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>frau1</th>\n",
       "      <td>118.0</td>\n",
       "      <td>28438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>3187.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.035703</td>\n",
       "      <td>0.065556</td>\n",
       "      <td>0.366968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nongerman</th>\n",
       "      <td>37.0</td>\n",
       "      <td>14876.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.023840</td>\n",
       "      <td>0.045538</td>\n",
       "      <td>0.189278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nongerman_male</th>\n",
       "      <td>22.0</td>\n",
       "      <td>9687.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>773.0</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.027673</td>\n",
       "      <td>0.052758</td>\n",
       "      <td>0.120702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nongerman_female</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5189.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.037927</td>\n",
       "      <td>0.068577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TP       TN     FP      FN  Precision    Recall  \\\n",
       "Subgroup                                                               \n",
       "frau1             118.0  28438.0  177.0  3187.0   0.400000  0.035703   \n",
       "nongerman          37.0  14876.0   36.0  1515.0   0.506849  0.023840   \n",
       "nongerman_male     22.0   9687.0   17.0   773.0   0.564103  0.027673   \n",
       "nongerman_female   15.0   5189.0   19.0   742.0   0.441176  0.019815   \n",
       "\n",
       "                        F1  Coverage (non-ambiguous)  \n",
       "Subgroup                                              \n",
       "frau1             0.065556                  0.366968  \n",
       "nongerman         0.045538                  0.189278  \n",
       "nongerman_male    0.052758                  0.120702  \n",
       "nongerman_female  0.037927                  0.068577  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def compute_confusion_metrics(pred_sets, y_true, subgroup_mask):\n",
    "    # Filter to non-ambiguous predictions and apply subgroup mask\n",
    "    mask = np.array([len(s) == 1 for s in pred_sets]) & subgroup_mask\n",
    "    if not np.any(mask):\n",
    "        return None  # no data to evaluate\n",
    "    \n",
    "    y_true_filtered = np.array(y_true)[mask]\n",
    "    y_pred_filtered = [list(s)[0] for i, s in enumerate(pred_sets) if len(s) == 1 and subgroup_mask[i]]\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true_filtered, y_pred_filtered, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true_filtered, y_pred_filtered, average=\"binary\", zero_division=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"TP\": tp,\n",
    "        \"TN\": tn,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1,\n",
    "        \"Coverage (non-ambiguous)\": np.mean(mask)\n",
    "    }\n",
    "\n",
    "#frau1_mask = cp_groups['frau1'] == 1\n",
    "#nongerman_mask = cp_groups['nongerman'] == 1\n",
    "#nongerman_male_mask = cp_groups['nongerman_male'] == 1\n",
    "#nongerman_female_mask = cp_groups['nongerman_female'] == 1\n",
    "#\n",
    "## Create a dictionary of subgroups\n",
    "#subgroups = {\n",
    "#    \"frau1\": frau1_mask,\n",
    "#    \"nongerman\": nongerman_mask,\n",
    "#    \"nongerman_male\": nongerman_male_mask,\n",
    "#    \"nongerman_female\": nongerman_female_mask\n",
    "#}\n",
    "\n",
    "subgroups = {\n",
    "    \"frau1\": (cp_groups[\"frau1\"] == 1).values,\n",
    "    \"nongerman\": (cp_groups[\"nongerman\"] == 1).values,\n",
    "    \"nongerman_male\": (cp_groups[\"nongerman_male\"] == 1).values,\n",
    "    \"nongerman_female\": (cp_groups[\"nongerman_female\"] == 1).values\n",
    "}\n",
    "\n",
    "# Example usage:\n",
    "results = {}\n",
    "for name, mask in subgroups.items():\n",
    "    metrics = compute_confusion_metrics(pred_sets_filtered, y_test_filtered, mask)\n",
    "    if metrics:\n",
    "        results[name] = metrics\n",
    "\n",
    "# Print nicely\n",
    "df_results = pd.DataFrame(results).T\n",
    "df_results.index.name = \"Subgroup\"\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f2ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
