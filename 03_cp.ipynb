{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07550eba",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad59357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julia/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/Users/julia/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "\n",
    "from utils import (\n",
    "    compute_nc_scores,\n",
    "    find_threshold,\n",
    "    predict_conformal_sets,\n",
    "    evaluate_sets,\n",
    "    summarize_by_indicator,\n",
    "    summarize_for_predicate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16090e24",
   "metadata": {},
   "source": [
    "## Data and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8eccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_calib_f = pd.read_csv(\"./output/X_calib_f.csv\") # 2015, w. protected attributes\n",
    "X_calib_s = pd.read_csv(\"./output/X_calib_s.csv\") # 2015, w/o protected attributes\n",
    "y_calib = pd.read_csv(\"./output/y_calib.csv\").iloc[:,0]\n",
    "\n",
    "X_test_f = pd.read_csv(\"./output/X_test_f.csv\")\n",
    "X_test_s = pd.read_csv(\"./output/X_test_s.csv\")\n",
    "y_test = pd.read_csv(\"./output/y_test.csv\").iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84eb551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_test = pd.read_csv(\"./output/preds_test.csv\")\n",
    "\n",
    "glm1 = load(\"./models/glm1.joblib\")\n",
    "glm2 = load(\"./models/glm2.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fbfe25",
   "metadata": {},
   "source": [
    "## Conformal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102e8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscoverage level\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2907a640",
   "metadata": {},
   "source": [
    "### Conformal - Logit Regression (w. protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_calib1 = glm1.predict_proba(X_calib_f)\n",
    "\n",
    "nc_scores1 = compute_nc_scores(probs_calib1, y_calib)\n",
    "\n",
    "q_hat1 = find_threshold(nc_scores1, alpha) # q_hat is data-driven threshold for classification\n",
    "print(f\"q_hat1: {q_hat1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be08fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With test data\n",
    "pred_sets1 = predict_conformal_sets(glm1, X_test_f, q_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With test data\n",
    "evaluation1 = evaluate_sets(pred_sets1, y_test)\n",
    "print(f\"Coverage1: {evaluation1['coverage']:.2f}\")\n",
    "print(f\"Avg. set size 1: {evaluation1['avg_size']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5827c80b",
   "metadata": {},
   "source": [
    "### Conformal - Logit Regression (w/o protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c9a2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_hat2: 0.6601\n"
     ]
    }
   ],
   "source": [
    "probs_calib2 = glm2.predict_proba(X_calib_s)\n",
    "\n",
    "nc_scores2 = compute_nc_scores(probs_calib2, y_calib)\n",
    "\n",
    "q_hat2 = find_threshold(nc_scores2, alpha) # q_hat is data-driven threshold for classification\n",
    "print(f\"q_hat2: {q_hat2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297c234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With test data\n",
    "pred_sets2 = predict_conformal_sets(glm2, X_test_s, q_hat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed2870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage2: 0.91\n",
      "Avg. set size 2: 1.13\n"
     ]
    }
   ],
   "source": [
    "# With test data\n",
    "evaluation2 = evaluate_sets(pred_sets2, y_test)\n",
    "print(f\"Coverage2: {evaluation2['coverage']:.2f}\")\n",
    "print(f\"Avg. set size 2: {evaluation2['avg_size']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244cff0",
   "metadata": {},
   "source": [
    "## Analyzing CP per group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c576df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression with protected attributes\n",
    "\n",
    "# Create cp_groups with the same index as X_test_f (and y_test)\n",
    "cp_groups = pd.DataFrame(index=X_test_f.index)\n",
    "cp_groups['pred_set'] = pd.Series(pred_sets1, index=X_test_f.index).apply(lambda s: {int(x) for x in s})\n",
    "cp_groups['true_label'] = y_test.reindex(X_test_f.index)\n",
    "cp_groups['frau1'] = X_test_f['frau1']\n",
    "\n",
    "cp_groups['nongerman'] = np.where(\n",
    "    X_test_f['maxdeutsch1'] == 0, \n",
    "    1, \n",
    "    0\n",
    ")\n",
    "cp_groups.loc[\n",
    "    X_test_f['maxdeutsch.Missing.'] == 1, \n",
    "    'nongerman'\n",
    "] = np.nan\n",
    "\n",
    "cp_groups['nongerman_male'] = np.where(\n",
    "    (cp_groups['nongerman'] == 1) & (cp_groups['frau1'] == 0),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "cp_groups['nongerman_female'] = np.where(\n",
    "    (cp_groups['nongerman'] == 1) & (cp_groups['frau1'] == 1),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "cp_groups = cp_groups.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bca9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression w/o protected attributes\n",
    "\n",
    "# Create cp_groups with the same index as X_test_s\n",
    "cp_groups2 = pd.DataFrame(index=X_test_s.index)\n",
    "\n",
    "# Assign prediction sets (assuming pred_sets2 aligns with X_test_s)\n",
    "cp_groups2['pred_set'] = pd.Series(pred_sets2, index=X_test_s.index).apply(lambda s: {int(x) for x in s})\n",
    "\n",
    "# Get true labels from y_test\n",
    "cp_groups2['true_label'] = y_test.reindex(X_test_s.index)\n",
    "\n",
    "# Bring back protected features from X_test_f (or siab_test)\n",
    "cp_groups2['frau1'] = X_test_f.loc[X_test_s.index, 'frau1']\n",
    "\n",
    "cp_groups2['nongerman'] = np.where(\n",
    "    X_test_f.loc[X_test_s.index, 'maxdeutsch1'] == 0,\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "cp_groups2.loc[\n",
    "    X_test_f.loc[X_test_s.index, 'maxdeutsch.Missing.'] == 1,\n",
    "    'nongerman'\n",
    "] = np.nan\n",
    "\n",
    "# Split by gender\n",
    "cp_groups2['nongerman_male'] = np.where(\n",
    "    (cp_groups2['nongerman'] == 1) & (cp_groups2['frau1'] == 0),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "cp_groups2['nongerman_female'] = np.where(\n",
    "    (cp_groups2['nongerman'] == 1) & (cp_groups2['frau1'] == 1),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "# Drop rows with missing data in any of the relevant columns\n",
    "cp_groups2 = cp_groups2.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590f875e",
   "metadata": {},
   "source": [
    "### Conditional Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc757c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Coverage  Avg Set Size  Num Samples\n",
      "Group                                                \n",
      "frau1             0.910554      1.146543        37095\n",
      "nongerman         0.911862      1.070847        17813\n",
      "nongerman_male    0.927047      1.045303        11103\n",
      "nongerman_female  0.886736      1.113115         6710\n"
     ]
    }
   ],
   "source": [
    "# Conditional coverage and set size\n",
    "\n",
    "# List of subgroup indicators to evaluate\n",
    "groups = ['frau1', 'nongerman', 'nongerman_male', 'nongerman_female']\n",
    "\n",
    "# Align pred_sets with y_test indices for easy filtering\n",
    "pred_sets_series = pd.Series(pred_sets2, index=y_test.index)\n",
    "\n",
    "# Prepare a list to collect results\n",
    "results = []\n",
    "\n",
    "for group in groups:\n",
    "    # Create a boolean mask for the current subgroup (True for indices in the subgroup)\n",
    "    mask = (cp_groups2[group] == 1)\n",
    "    # Align the mask to y_test index (in case cp_groups has a subset of test indices)\n",
    "    mask_aligned = mask.reindex(y_test.index, fill_value=False)\n",
    "    \n",
    "    # Filter true labels and prediction sets for this subgroup\n",
    "    group_y = y_test[mask_aligned]             # true labels for this subgroup\n",
    "    group_pred_sets = pred_sets_series[mask_aligned]  # prediction sets for this subgroup\n",
    "    \n",
    "    # Compute coverage: fraction of cases where true label is in the prediction set\n",
    "    coverage = np.mean([\n",
    "        1 if true_label in pred_set else 0 \n",
    "        for true_label, pred_set in zip(group_y, group_pred_sets)\n",
    "    ])\n",
    "    # Compute average prediction set size for this subgroup\n",
    "    avg_set_size = np.mean([len(pred_set) for pred_set in group_pred_sets])\n",
    "    \n",
    "    # Store the results (optionally multiply coverage by 100 if you want percentage)\n",
    "    results.append({\n",
    "        'Group': group,\n",
    "        'Coverage': coverage,\n",
    "        'Avg Set Size': avg_set_size,\n",
    "        'Num Samples': mask_aligned.sum()  # number of test samples in this subgroup\n",
    "    })\n",
    "\n",
    "# Create a DataFrame for clear tabular display of the results\n",
    "coverage_results = pd.DataFrame(results).set_index('Group')\n",
    "print(coverage_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4155dd8f",
   "metadata": {},
   "source": [
    "### True Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fedec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall true_label distribution:\n",
      "true_label\n",
      "0    75876\n",
      "1    11107\n",
      "Name: count, dtype: int64\n",
      "As proportions:\n",
      "true_label\n",
      "0    0.872308\n",
      "1    0.127692\n",
      "Name: proportion, dtype: float64\n",
      "P(true_label=1): 0.1277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subgroups true class label distributions\n",
    "\n",
    "# Overall distribution of true_label\n",
    "print(\"Overall true_label distribution:\")\n",
    "print(cp_groups2['true_label'].value_counts().sort_index())\n",
    "print(\"As proportions:\")\n",
    "print(cp_groups2['true_label'].value_counts(normalize=True).sort_index())\n",
    "print(f\"P(true_label=1): {cp_groups2['true_label'].mean():.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428b7adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution conditional on frau1:\n",
      "P(true_label=1 | frau1=0): 0.1235 (n=49888)\n",
      "P(true_label=1 | frau1=1): 0.1334 (n=37095)\n",
      "\n",
      "Total observations: 86983 (female: n=37095, male: n=49888)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution conditional on frau1\n",
    "print(\"Distribution conditional on frau1:\")\n",
    "for frau_val in [0, 1]:\n",
    "    subset = cp_groups2[cp_groups2['frau1'] == frau_val] # Get all females\n",
    "    prop_positive = subset['true_label'].mean() # What % of females have true_label=1?\n",
    "    print(f\"P(true_label=1 | frau1={frau_val}): {prop_positive:.4f} (n={len(subset)})\")\n",
    "print()\n",
    "\n",
    "# Add total counts\n",
    "n_female = (cp_groups2['frau1'] == 1).sum()\n",
    "n_male = (cp_groups2['frau1'] == 0).sum()\n",
    "print(f\"Total observations: {len(cp_groups2)} (female: n={n_female}, male: n={n_male})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce790ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution conditional on nongerman\n",
    "print(\"Distribution conditional on nongerman:\")\n",
    "for ng_val in [0, 1]:\n",
    "    subset = cp_groups[cp_groups['nongerman'] == ng_val]\n",
    "    prop_positive = subset['true_label'].mean()\n",
    "    print(f\"P(true_label=1 | nongerman={ng_val}): {prop_positive:.4f} (n={len(subset)})\")\n",
    "print()\n",
    "\n",
    "# Add total counts\n",
    "n_german = (cp_groups['nongerman'] == 0).sum()\n",
    "n_nongerman = (cp_groups['nongerman'] == 1).sum()\n",
    "print(f\"Total observations: {len(cp_groups)} (german: n={n_german}, nongerman: n={n_nongerman})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e6c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution conditional on nongerman_male and nongerman_female\n",
    "print(\"Distribution conditional on nongerman subgroups:\")\n",
    "if 'nongerman_male' in cp_groups.columns:\n",
    "    for nm_val in [0, 1]:\n",
    "        subset = cp_groups[cp_groups['nongerman_male'] == nm_val]\n",
    "        prop_positive = subset['true_label'].mean()\n",
    "        print(f\"P(true_label=1 | nongerman_male={nm_val}): {prop_positive:.4f} (n={len(subset)})\")\n",
    "\n",
    "if 'nongerman_female' in cp_groups.columns:\n",
    "    for nf_val in [0, 1]:\n",
    "        subset = cp_groups[cp_groups['nongerman_female'] == nf_val]\n",
    "        prop_positive = subset['true_label'].mean()\n",
    "        print(f\"P(true_label=1 | nongerman_female={nf_val}): {prop_positive:.4f} (n={len(subset)})\")\n",
    "print()\n",
    "\n",
    "# Add total counts\n",
    "n_german_male = (cp_groups['nongerman_male'] == 0).sum()\n",
    "n_nongerman_male = (cp_groups['nongerman_male'] == 1).sum()\n",
    "print(f\"Total observations: {len(cp_groups)} (other: n={n_german_male}, nongerman male: n={n_nongerman_male})\")\n",
    "print()\n",
    "\n",
    "# Add total counts\n",
    "n_german_female = (cp_groups['nongerman_female'] == 0).sum()\n",
    "n_nongerman_female = (cp_groups['nongerman_female'] == 1).sum()\n",
    "print(f\"Total observations: {len(cp_groups)} (other: n={n_german_female}, nongerman female: n={n_nongerman_female})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d07f32",
   "metadata": {},
   "source": [
    "### Prediction Sets Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf20f9f",
   "metadata": {},
   "source": [
    "#### Summarize for Predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95d1062f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among cases where pred_set == {0}:\n",
      "  Proportion true_label == 1:        0.097\n",
      "  Proportion frau1 == 1:             0.415\n",
      "  Proportion nongerman == 1:         0.219\n",
      "  Proportion nongerman_male == 1:    0.140\n",
      "  Proportion nongerman_female == 1:  0.078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_for_predicate(\n",
    "    cp_groups2,\n",
    "    predicate=lambda s: set(s) == {0},\n",
    "    description=\"== {0}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "513af460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among cases where pred_set == {1}:\n",
      "  Proportion true_label == 1:        0.435\n",
      "  Proportion frau1 == 1:             0.432\n",
      "  Proportion nongerman == 1:         0.073\n",
      "  Proportion nongerman_male == 1:    0.030\n",
      "  Proportion nongerman_female == 1:  0.043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_for_predicate(\n",
    "    cp_groups2,\n",
    "    predicate=lambda s: set(s) == {1},\n",
    "    description=\"== {1}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f322fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among cases where pred_set == {0,1}:\n",
      "  Proportion true_label == 1:        0.319\n",
      "  Proportion frau1 == 1:             0.504\n",
      "  Proportion nongerman == 1:         0.117\n",
      "  Proportion nongerman_male == 1:    0.047\n",
      "  Proportion nongerman_female == 1:  0.070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summarize_for_predicate(\n",
    "    cp_groups2,\n",
    "    predicate=lambda s: set(s) == {0,1},\n",
    "    description=\"== {0,1}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eed81a7",
   "metadata": {},
   "source": [
    "#### Summarize by Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1041681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts:\n",
      "pred_set\n",
      "{0}       75435\n",
      "{0, 1}    10777\n",
      "{1}         771\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportions:\n",
      "pred_set\n",
      "{0}       0.867238\n",
      "{0, 1}    0.123898\n",
      "{1}       0.008864\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Baselines CP\n",
    "\n",
    "print(\"Value counts:\")\n",
    "print(cp_groups2['pred_set'].value_counts())\n",
    "print(\"\\nProportions:\")\n",
    "print(cp_groups2['pred_set'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d4da4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counts by gender:\n",
      "\n",
      "        is_ambiguous  is_zero_only  is_one_only\n",
      "frau1                                          \n",
      "male            5341         44109          438\n",
      "female          5436         31326          333\n",
      "\n",
      "Percentages by gender:\n",
      "\n",
      "        is_ambiguous  is_zero_only  is_one_only\n",
      "frau1                                          \n",
      "male       10.705981     88.416052     0.877967\n",
      "female     14.654266     84.448039     0.897695\n"
     ]
    }
   ],
   "source": [
    "# Summarize for frau1 == 1 (vs 0)\n",
    "counts_female, pct_female = summarize_by_indicator(\n",
    "    cp_groups2,\n",
    "    indicator_col='frau1',\n",
    "    positive_label='female',\n",
    "    negative_label='male'\n",
    ")\n",
    "\n",
    "print(\"\\nCounts by gender:\\n\")\n",
    "print(counts_female)\n",
    "print(\"\\nPercentages by gender:\\n\")\n",
    "print(pct_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1533a7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by nationality (German vs non‐German):\n",
      "\n",
      "            is_ambiguous  is_zero_only  is_one_only\n",
      "nongerman                                          \n",
      "German              9515         58940          715\n",
      "non‐German          1262         16495           56\n",
      "\n",
      "Percentages by nationality:\n",
      "\n",
      "            is_ambiguous  is_zero_only  is_one_only\n",
      "nongerman                                          \n",
      "German         13.755964     85.210351     1.033685\n",
      "non‐German      7.084713     92.600909     0.314377\n"
     ]
    }
   ],
   "source": [
    "# Summarize for nongerman == 1 (vs 0)\n",
    "counts_ng, pct_ng = summarize_by_indicator(\n",
    "    cp_groups2,\n",
    "    indicator_col='nongerman',\n",
    "    positive_label='non‐German',\n",
    "    negative_label='German'\n",
    ")\n",
    "\n",
    "print(\"Counts by nationality (German vs non‐German):\\n\")\n",
    "print(counts_ng)\n",
    "print(\"\\nPercentages by nationality:\\n\")\n",
    "print(pct_ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57ea6ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counts for non‐German Male vs Others:\n",
      "\n",
      "                 is_ambiguous  is_zero_only  is_one_only\n",
      "nongerman_male                                          \n",
      "Others                  10274         64858          748\n",
      "non‐German Male           503         10577           23\n",
      "\n",
      "Percentages for non‐German Male vs Others:\n",
      "\n",
      "                 is_ambiguous  is_zero_only  is_one_only\n",
      "nongerman_male                                          \n",
      "Others              13.539800     85.474433     0.985767\n",
      "non‐German Male      4.530307     95.262542     0.207151\n"
     ]
    }
   ],
   "source": [
    "# Summarize for nongerman_male == 1 (vs 0)\n",
    "counts_ng_male, pct_ng_male = summarize_by_indicator(\n",
    "    cp_groups2,\n",
    "    indicator_col='nongerman_male',\n",
    "    positive_label='non‐German Male',\n",
    "    negative_label='Others'\n",
    ")\n",
    "\n",
    "print(\"\\nCounts for non‐German Male vs Others:\\n\")\n",
    "print(counts_ng_male)\n",
    "print(\"\\nPercentages for non‐German Male vs Others:\\n\")\n",
    "print(pct_ng_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d7d5e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counts for non‐German Female vs Others:\n",
      "\n",
      "                   is_ambiguous  is_zero_only  is_one_only\n",
      "nongerman_female                                          \n",
      "Others                    10018         69517          738\n",
      "non‐German Female           759          5918           33\n",
      "\n",
      "Percentages for non‐German Female vs Others:\n",
      "\n",
      "                   is_ambiguous  is_zero_only  is_one_only\n",
      "nongerman_female                                          \n",
      "Others                12.479912     86.600725     0.919363\n",
      "non‐German Female     11.311475     88.196721     0.491803\n"
     ]
    }
   ],
   "source": [
    "# Summarize for nongerman_female == 1 (vs 0)\n",
    "counts_ng_female, pct_ng_female = summarize_by_indicator(\n",
    "    cp_groups2,\n",
    "    indicator_col='nongerman_female',\n",
    "    positive_label='non‐German Female',\n",
    "    negative_label='Others'\n",
    ")\n",
    "\n",
    "print(\"\\nCounts for non‐German Female vs Others:\\n\")\n",
    "print(counts_ng_female)\n",
    "print(\"\\nPercentages for non‐German Female vs Others:\\n\")\n",
    "print(pct_ng_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7553ed",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9cbe613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (excluding ambiguous cases):\n",
      "[[70090   455]\n",
      " [ 7576   351]]\n",
      "Accuracy:  0.898\n",
      "Precision: 0.435\n",
      "Recall:    0.044\n",
      "F1 Score:  0.080\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 1. Filter out ambiguous prediction sets (where pred_set == {0,1})\n",
    "confident_indices = [idx for idx, pset in enumerate(pred_sets2) if pset != {0, 1}]\n",
    "\n",
    "# If there are no confident predictions, handle that case\n",
    "if len(confident_indices) == 0:\n",
    "    print(\"No confident predictions (all predictions were ambiguous). Confusion matrix cannot be computed.\")\n",
    "else:\n",
    "    # 2. Extract predicted labels from the remaining sets\n",
    "    y_pred_filtered = []\n",
    "    for idx in confident_indices:\n",
    "        pset = pred_sets2[idx]\n",
    "        # pset can only be {0} or {1} here\n",
    "        predicted_label = 0 if pset == {0} else 1\n",
    "        y_pred_filtered.append(predicted_label)\n",
    "\n",
    "    # 3. Align predicted labels with the corresponding true labels\n",
    "    # Use the same indices to filter y_test\n",
    "    y_true_filtered = [y_test.iloc[idx] for idx in confident_indices]\n",
    "\n",
    "    # 4. Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true_filtered, y_pred_filtered)\n",
    "    print(\"Confusion matrix (excluding ambiguous cases):\")\n",
    "    print(cm)\n",
    "\n",
    "# Extract individual components\n",
    "TN, FP, FN, TP = cm.ravel()  # Unpacks the 2x2 matrix into values\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else float('nan')\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else float('nan')\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else float('nan')\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy:  {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1 Score:  {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "009dc272",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = cp_groups2.index\n",
    "# Align arrays\n",
    "pred_sets_filtered = [pred_sets2[i] for i in valid_idx]\n",
    "y_test_filtered = np.array(y_test)[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "693daaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Subgroup",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Coverage (non-ambiguous)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0602b2d5-4027-4114-ba48-a866e6e511b4",
       "rows": [
        [
         "frau1",
         "129.0",
         "28212.0",
         "204.0",
         "3114.0",
         "0.38738738738738737",
         "0.039777983348751156",
         "0.07214765100671142",
         "0.36396767184392353"
        ],
        [
         "nongerman",
         "27.0",
         "14954.0",
         "29.0",
         "1541.0",
         "0.48214285714285715",
         "0.01721938775510204",
         "0.0332512315270936",
         "0.19027856017842568"
        ],
        [
         "nongerman_male",
         "14.0",
         "9776.0",
         "9.0",
         "801.0",
         "0.6086956521739131",
         "0.01717791411042945",
         "0.03341288782816229",
         "0.12186289274915788"
        ],
        [
         "nongerman_female",
         "13.0",
         "5178.0",
         "20.0",
         "740.0",
         "0.3939393939393939",
         "0.017264276228419653",
         "0.03307888040712468",
         "0.06841566742926779"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Coverage (non-ambiguous)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subgroup</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>frau1</th>\n",
       "      <td>129.0</td>\n",
       "      <td>28212.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>3114.0</td>\n",
       "      <td>0.387387</td>\n",
       "      <td>0.039778</td>\n",
       "      <td>0.072148</td>\n",
       "      <td>0.363968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nongerman</th>\n",
       "      <td>27.0</td>\n",
       "      <td>14954.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.017219</td>\n",
       "      <td>0.033251</td>\n",
       "      <td>0.190279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nongerman_male</th>\n",
       "      <td>14.0</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.017178</td>\n",
       "      <td>0.033413</td>\n",
       "      <td>0.121863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nongerman_female</th>\n",
       "      <td>13.0</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.017264</td>\n",
       "      <td>0.033079</td>\n",
       "      <td>0.068416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TP       TN     FP      FN  Precision    Recall  \\\n",
       "Subgroup                                                               \n",
       "frau1             129.0  28212.0  204.0  3114.0   0.387387  0.039778   \n",
       "nongerman          27.0  14954.0   29.0  1541.0   0.482143  0.017219   \n",
       "nongerman_male     14.0   9776.0    9.0   801.0   0.608696  0.017178   \n",
       "nongerman_female   13.0   5178.0   20.0   740.0   0.393939  0.017264   \n",
       "\n",
       "                        F1  Coverage (non-ambiguous)  \n",
       "Subgroup                                              \n",
       "frau1             0.072148                  0.363968  \n",
       "nongerman         0.033251                  0.190279  \n",
       "nongerman_male    0.033413                  0.121863  \n",
       "nongerman_female  0.033079                  0.068416  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def compute_confusion_metrics(pred_sets, y_true, subgroup_mask):\n",
    "    # Filter to non-ambiguous predictions and apply subgroup mask\n",
    "    mask = np.array([len(s) == 1 for s in pred_sets]) & subgroup_mask\n",
    "    if not np.any(mask):\n",
    "        return None  # no data to evaluate\n",
    "    \n",
    "    y_true_filtered = np.array(y_true)[mask]\n",
    "    y_pred_filtered = [list(s)[0] for i, s in enumerate(pred_sets) if len(s) == 1 and subgroup_mask[i]]\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true_filtered, y_pred_filtered, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true_filtered, y_pred_filtered, average=\"binary\", zero_division=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"TP\": tp,\n",
    "        \"TN\": tn,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1,\n",
    "        \"Coverage (non-ambiguous)\": np.mean(mask)\n",
    "    }\n",
    "\n",
    "#frau1_mask = cp_groups['frau1'] == 1\n",
    "#nongerman_mask = cp_groups['nongerman'] == 1\n",
    "#nongerman_male_mask = cp_groups['nongerman_male'] == 1\n",
    "#nongerman_female_mask = cp_groups['nongerman_female'] == 1\n",
    "#\n",
    "## Create a dictionary of subgroups\n",
    "#subgroups = {\n",
    "#    \"frau1\": frau1_mask,\n",
    "#    \"nongerman\": nongerman_mask,\n",
    "#    \"nongerman_male\": nongerman_male_mask,\n",
    "#    \"nongerman_female\": nongerman_female_mask\n",
    "#}\n",
    "\n",
    "subgroups = {\n",
    "    \"frau1\": (cp_groups2[\"frau1\"] == 1).values,\n",
    "    \"nongerman\": (cp_groups2[\"nongerman\"] == 1).values,\n",
    "    \"nongerman_male\": (cp_groups2[\"nongerman_male\"] == 1).values,\n",
    "    \"nongerman_female\": (cp_groups2[\"nongerman_female\"] == 1).values\n",
    "}\n",
    "\n",
    "# Example usage:\n",
    "results = {}\n",
    "for name, mask in subgroups.items():\n",
    "    metrics = compute_confusion_metrics(pred_sets_filtered, y_test_filtered, mask)\n",
    "    if metrics:\n",
    "        results[name] = metrics\n",
    "\n",
    "# Print nicely\n",
    "df_results = pd.DataFrame(results).T\n",
    "df_results.index.name = \"Subgroup\"\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f2ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
