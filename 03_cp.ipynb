{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07550eba",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad59357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julia/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/Users/julia/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "\n",
    "from utils import (\n",
    "    compute_nc_scores,\n",
    "    find_threshold,\n",
    "    predict_conformal_sets,\n",
    "    evaluate_sets,\n",
    "    summarize_by_indicator,\n",
    "    summarize_for_predicate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16090e24",
   "metadata": {},
   "source": [
    "## Data and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8eccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_calib_f = pd.read_csv(\"./output/X_calib_f.csv\") # 2015, w. protected attributes\n",
    "#X_calib_s = pd.read_csv(\"./output/X_calib_s.csv\") # 2015, w/o protected attributes\n",
    "y_calib = pd.read_csv(\"./output/y_calib.csv\").iloc[:,0]\n",
    "\n",
    "X_test_f = pd.read_csv(\"./output/X_test_f.csv\")\n",
    "#X_test_s = pd.read_csv(\"./output/X_test_s.csv\")\n",
    "y_test = pd.read_csv(\"./output/y_test.csv\").iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_test = pd.read_csv(\"./output/preds_test.csv\")\n",
    "\n",
    "glm1 = load(\"./models/glm1.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fbfe25",
   "metadata": {},
   "source": [
    "## Conformal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102e8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscoverage level\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdce0aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_hat: 0.6604\n"
     ]
    }
   ],
   "source": [
    "probs_calib = glm1.predict_proba(X_calib_f)\n",
    "\n",
    "nc_scores = compute_nc_scores(probs_calib, y_calib)\n",
    "\n",
    "q_hat = find_threshold(nc_scores, alpha) # q_hat is data-driven threshold for classification\n",
    "print(f\"q_hat: {q_hat:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be08fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With test data\n",
    "pred_sets = predict_conformal_sets(glm1, X_test_f, q_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2342aaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage: 0.91\n",
      "Avg. set size: 1.13\n"
     ]
    }
   ],
   "source": [
    "# With test data\n",
    "evaluation = evaluate_sets(pred_sets, y_test)\n",
    "print(f\"Coverage: {evaluation['coverage']:.2f}\")\n",
    "print(f\"Avg. set size: {evaluation['avg_size']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244cff0",
   "metadata": {},
   "source": [
    "## Analyzing CP per group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c576df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cp_groups with the same index as X_test_f (and y_test)\n",
    "cp_groups = pd.DataFrame(index=X_test_f.index)\n",
    "cp_groups['pred_set'] = pd.Series(pred_sets, index=X_test_f.index).apply(lambda s: {int(x) for x in s})\n",
    "cp_groups['true_label'] = y_test.reindex(X_test_f.index)\n",
    "cp_groups['frau1'] = X_test_f['frau1']\n",
    "\n",
    "cp_groups['nongerman'] = np.where(\n",
    "    X_test_f['maxdeutsch1'] == 0, \n",
    "    1, \n",
    "    0\n",
    ")\n",
    "cp_groups.loc[\n",
    "    X_test_f['maxdeutsch.Missing.'] == 1, \n",
    "    'nongerman'\n",
    "] = np.nan\n",
    "\n",
    "cp_groups['nongerman_male'] = np.where(\n",
    "    (cp_groups['nongerman'] == 1) & (cp_groups['frau1'] == 0),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "cp_groups['nongerman_female'] = np.where(\n",
    "    (cp_groups['nongerman'] == 1) & (cp_groups['frau1'] == 1),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "cp_groups = cp_groups.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1eaa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baselines\n",
    "\n",
    "print(\"Value counts:\")\n",
    "print(cp_groups['pred_set'].value_counts())\n",
    "print(\"\\nProportions:\")\n",
    "print(cp_groups['pred_set'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d1062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_for_predicate(\n",
    "    cp_groups,\n",
    "    predicate=lambda s: set(s) == {0},\n",
    "    description=\"== {0}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513af460",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_for_predicate(\n",
    "    cp_groups,\n",
    "    predicate=lambda s: set(s) == {1},\n",
    "    description=\"== {1}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f322fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_for_predicate(\n",
    "    cp_groups,\n",
    "    predicate=lambda s: set(s) == {0,1},\n",
    "    description=\"== {0,1}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4da4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize for frau1 == 1 (vs 0)\n",
    "counts_female, pct_female = summarize_by_indicator(\n",
    "    cp_groups,\n",
    "    indicator_col='frau1',\n",
    "    positive_label='female',\n",
    "    negative_label='male'\n",
    ")\n",
    "\n",
    "print(\"\\nCounts by gender:\\n\")\n",
    "print(counts_female)\n",
    "print(\"\\nPercentages by gender:\\n\")\n",
    "print(pct_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize for nongerman == 1 (vs 0)\n",
    "counts_ng, pct_ng = summarize_by_indicator(\n",
    "    cp_groups,\n",
    "    indicator_col='nongerman',\n",
    "    positive_label='non‐German',\n",
    "    negative_label='German'\n",
    ")\n",
    "\n",
    "print(\"Counts by nationality (German vs non‐German):\\n\")\n",
    "print(counts_ng)\n",
    "print(\"\\nPercentages by nationality:\\n\")\n",
    "print(pct_ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize for nongerman_male == 1 (vs 0)\n",
    "counts_ng_male, pct_ng_male = summarize_by_indicator(\n",
    "    cp_groups,\n",
    "    indicator_col='nongerman_male',\n",
    "    positive_label='non‐German Male',\n",
    "    negative_label='Others'\n",
    ")\n",
    "\n",
    "print(\"\\nCounts for non‐German Male vs Others:\\n\")\n",
    "print(counts_ng_male)\n",
    "print(\"\\nPercentages for non‐German Male vs Others:\\n\")\n",
    "print(pct_ng_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize for nongerman_female == 1 (vs 0)\n",
    "counts_ng_female, pct_ng_female = summarize_by_indicator(\n",
    "    cp_groups,\n",
    "    indicator_col='nongerman_female',\n",
    "    positive_label='non‐German Female',\n",
    "    negative_label='Others'\n",
    ")\n",
    "\n",
    "print(\"\\nCounts for non‐German Female vs Others:\\n\")\n",
    "print(counts_ng_female)\n",
    "print(\"\\nPercentages for non‐German Female vs Others:\\n\")\n",
    "print(pct_ng_female)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
