{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7bebcf4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3682bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When working in AI LRZ\n",
    "%cd ~/projects/cma_f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08327b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julia/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/Users/julia/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import make_scorer, confusion_matrix\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate # GroupKFold, GridSearchCV,\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from joblib import dump\n",
    "\n",
    "from utils import (\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9275fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load universe definitions from YAML\n",
    "import yaml\n",
    "\n",
    "with open(\"universes.yaml\") as f:\n",
    "    universes = yaml.safe_load(f)\n",
    "\n",
    "# Access by ID\n",
    "#universe_id = 12\n",
    "#config = next(u for u in universes if u[\"id\"] == universe_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298f2b2",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa524e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f = pd.read_csv(\"./output/X_train_f.csv\") # 2010 - 2014, w. protected attributes\n",
    "X_train_s = pd.read_csv(\"./output/X_train_s.csv\") # 2010 - 2014, w/o protected attributes\n",
    "y_train = pd.read_csv(\"./output/y_train.csv\").iloc[:,0]\n",
    "\n",
    "X_test_f = pd.read_csv(\"./output/X_test_f.csv\")\n",
    "X_test_s = pd.read_csv(\"./output/X_test_s.csv\")\n",
    "y_test = pd.read_csv(\"./output/y_test.csv\").iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d403690f",
   "metadata": {},
   "source": [
    "## Multiverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28fde7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_type, X, y):\n",
    "    if model_type == \"logreg\":\n",
    "        model = LogisticRegression(penalty=None, solver=\"newton-cg\", max_iter=1000, random_state=19)\n",
    "    elif model_type == \"penalized_logreg\":\n",
    "        model = LogisticRegression(penalty=\"l2\", C=1.0, solver=\"newton-cg\", max_iter=1000, random_state=19)\n",
    "    elif model_type == \"rf\":\n",
    "        model = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=19)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e83f5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test feature sets\n",
    "feature_sets_train = {\n",
    "    \"with_protected\": X_train_f,\n",
    "    \"without_protected\": X_train_s\n",
    "}\n",
    "feature_sets_test = {\n",
    "    \"with_protected\": X_test_f,\n",
    "    \"without_protected\": X_test_s\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0123b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds\n",
    "threshold_policies = {\n",
    "    \"top15\": 0.15,\n",
    "    \"top30\": 0.30\n",
    "}\n",
    "\n",
    "#    \"top45\": 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84fca6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group universes by (model_type, feature_flag)\n",
    "from collections import defaultdict\n",
    "universe_groups = defaultdict(list)\n",
    "for cfg in universes:\n",
    "    key = (cfg[\"model\"], cfg[\"feature_set\"])\n",
    "    universe_groups[key].append(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17513cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: logreg with with_protected features\n",
      "Predicted universe 1: logreg, with_protected, top15\n",
      "Predicted universe 2: logreg, with_protected, top30\n",
      "Training model: logreg with without_protected features\n",
      "Predicted universe 3: logreg, without_protected, top15\n",
      "Predicted universe 4: logreg, without_protected, top30\n",
      "Training model: penalized_logreg with with_protected features\n",
      "Predicted universe 5: penalized_logreg, with_protected, top15\n",
      "Predicted universe 6: penalized_logreg, with_protected, top30\n",
      "Training model: penalized_logreg with without_protected features\n",
      "Predicted universe 7: penalized_logreg, without_protected, top15\n",
      "Predicted universe 8: penalized_logreg, without_protected, top30\n",
      "Training model: rf with with_protected features\n",
      "Predicted universe 9: rf, with_protected, top15\n",
      "Predicted universe 10: rf, with_protected, top30\n",
      "Training model: rf with without_protected features\n",
      "Predicted universe 11: rf, without_protected, top15\n",
      "Predicted universe 12: rf, without_protected, top30\n"
     ]
    }
   ],
   "source": [
    "# Train one model per (model_type, feature_flag), then apply all thresholds\n",
    "\n",
    "predictions_by_universe = {}\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "for (model_type, feature_flag), cfgs in universe_groups.items():\n",
    "    print(f\"Training model: {model_type} with {feature_flag} features\")\n",
    "    X_train_used = feature_sets_train[feature_flag]\n",
    "    model = train_model(model_type, X_train_used, y_train)\n",
    "\n",
    "    # Save model\n",
    "    universe_id = f\"{model_type}_{feature_flag}\"\n",
    "    dump(model, f\"./models/{universe_id}.joblib\")\n",
    "\n",
    "    # Predict probabilities on test set\n",
    "    X_test_used = feature_sets_test[feature_flag]\n",
    "    probs = model.predict_proba(X_test_used)[:, 1]\n",
    "\n",
    "    for cfg in cfgs:\n",
    "        uid = cfg[\"id\"]\n",
    "        threshold_key = cfg[\"threshold_policy\"]\n",
    "        k = threshold_policies[threshold_key]\n",
    "        threshold_value = np.sort(probs)[::-1][int(k * len(probs))]\n",
    "        binary_preds = (probs >= threshold_value).astype(int)\n",
    "        predictions_by_universe[uid] = binary_preds\n",
    "        print(f\"Predicted universe {uid}: {model_type}, {feature_flag}, {threshold_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0315510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results into a DataFrame for inspection/saving\n",
    "y_test_array = np.array(y_test).reshape(-1, 1)\n",
    "y_df = pd.DataFrame(y_test_array, columns=[\"y_test\"])\n",
    "\n",
    "all_preds = []\n",
    "for uid in sorted(predictions_by_universe):\n",
    "    col_name = f\"preds_u{uid}\"\n",
    "    col_data = pd.DataFrame(predictions_by_universe[uid], columns=[col_name])\n",
    "    all_preds.append(col_data)\n",
    "\n",
    "preds_test = pd.concat([y_df] + all_preds, axis=1)\n",
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "preds_test.to_csv(\"./output/preds_test.csv\", index=False)\n",
    "\n",
    "#print(\"Saved combined predictions to ./output/preds_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c5ed6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/6qcvyjh51cg86vrxn3xs8c_40000gn/T/ipykernel_4808/2427680122.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  universe_df_escaped = universe_df.applymap(escape_latex_str)\n"
     ]
    }
   ],
   "source": [
    "# Create LaTeX summary table for universes\n",
    "def escape_latex_str(val):\n",
    "    return str(val).replace('_', '\\\\_')\n",
    "\n",
    "universe_df = pd.DataFrame(universes)\n",
    "\n",
    "# Rename and reorder columns\n",
    "universe_df = universe_df.rename(columns={\n",
    "    \"feature_set\": \"feature set\",\n",
    "    \"threshold_policy\": \"threshold\"\n",
    "})\n",
    "universe_df = universe_df[[\"id\", \"model\", \"feature set\", \"threshold\"]]\n",
    "\n",
    "universe_df_escaped = universe_df.applymap(escape_latex_str)\n",
    "\n",
    "latex_table = universe_df_escaped.to_latex(\n",
    "    index=False,\n",
    "    caption=\"Universe configuration overview\",\n",
    "    label=\"tab:universe_summary\",\n",
    "    escape=False\n",
    ")\n",
    "\n",
    "with open(\"./output/universe_summary.tex\", \"w\") as f:\n",
    "    f.write(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac19281",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e22ab764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect confusion matrices for all universes\n",
    "confusion_matrices = []\n",
    "\n",
    "for uid, preds in predictions_by_universe.items():\n",
    "    cm = confusion_matrix(y_test, preds, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    confusion_matrices.append({\n",
    "        \"id\": uid,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"tp\": tp,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6241cff9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/var/folders/h7/6qcvyjh51cg86vrxn3xs8c_40000gn/T/ipykernel_4808/2575985207.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m confusion_df = pd.DataFrame(confusion_matrices)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m confusion_df = confusion_df.sort_values(\u001b[33m\"id\"\u001b[39m)\n\u001b[32m      3\u001b[39m print(confusion_df)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#confusion_df.to_csv(\"./output/confusion_matrices.csv\", index=False)\u001b[39;00m\n",
      "\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7185\u001b[39m             )\n\u001b[32m   7186\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m len(by):\n\u001b[32m   7187\u001b[39m             \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[32m   7188\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m7189\u001b[39m             k = self._get_label_or_level_values(by[\u001b[32m0\u001b[39m], axis=axis)\n\u001b[32m   7190\u001b[39m \n\u001b[32m   7191\u001b[39m             \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[32m   7192\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'id'"
     ]
    }
   ],
   "source": [
    "confusion_df = pd.DataFrame(confusion_matrices)\n",
    "confusion_df = confusion_df.sort_values(\"id\")\n",
    "print(confusion_df)\n",
    "#confusion_df.to_csv(\"./output/confusion_matrices.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
