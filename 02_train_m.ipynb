{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7bebcf4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08327b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate # GroupKFold, GridSearchCV,\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from joblib import dump\n",
    "\n",
    "from utils import (\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9275fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load universe definitions from YAML\n",
    "import yaml\n",
    "\n",
    "with open(\"universes.yaml\") as f:\n",
    "    universes = yaml.safe_load(f)\n",
    "\n",
    "# Access by ID\n",
    "#universe_id = 12\n",
    "#config = next(u for u in universes if u[\"id\"] == universe_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298f2b2",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa524e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f = pd.read_csv(\"./output/X_train_f.csv\") # 2010 - 2014, w. protected attributes\n",
    "X_train_s = pd.read_csv(\"./output/X_train_s.csv\") # 2010 - 2014, w/o protected attributes\n",
    "y_train = pd.read_csv(\"./output/y_train.csv\").iloc[:,0]\n",
    "\n",
    "X_test_f = pd.read_csv(\"./output/X_test_f.csv\")\n",
    "X_test_s = pd.read_csv(\"./output/X_test_s.csv\")\n",
    "y_test = pd.read_csv(\"./output/y_test.csv\").iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d403690f",
   "metadata": {},
   "source": [
    "## Multiverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02342563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28fde7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_type, X, y):\n",
    "    if model_type == \"logreg\":\n",
    "        model = LogisticRegression(penalty=None, solver=\"newton-cg\", max_iter=1000)\n",
    "    elif model_type == \"penalized_logreg\":\n",
    "        model = LogisticRegression(penalty=\"l2\", C=1.0, solver=\"newton-cg\", max_iter=1000)\n",
    "    elif model_type == \"rf\":\n",
    "        model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8716fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = {}  # Dictionary to store trained models by universe ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84a9cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure models directory exists\n",
    "os.makedirs(\"./models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cda953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for universe 1: logreg with with_protected features\n",
      "Trained model for universe 2: logreg with with_protected features\n",
      "Trained model for universe 3: logreg with with_protected features\n",
      "Trained model for universe 4: logreg with without_protected features\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown feature flag: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_flag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m model = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_used\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Store the trained model\u001b[39;00m\n\u001b[32m     22\u001b[39m trained_models[uid] = model\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model_type, X, y)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown model type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1350\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1348\u001b[39m     n_threads = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1350\u001b[39m fold_coefs_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1364\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m fold_coefs_, _, n_iter_ = \u001b[38;5;28mzip\u001b[39m(*fold_coefs_)\n\u001b[32m   1376\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/sklearn/utils/parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:475\u001b[39m, in \u001b[36m_logistic_regression_path\u001b[39m\u001b[34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[39m\n\u001b[32m    473\u001b[39m     l2_reg_strength = \u001b[32m1.0\u001b[39m / (C * sw_sum)\n\u001b[32m    474\u001b[39m     args = (X, target, sample_weight, l2_reg_strength, n_threads)\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     w0, n_iter_i = \u001b[43m_newton_cg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_hess\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m solver == \u001b[33m\"\u001b[39m\u001b[33mnewton-cholesky\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    486\u001b[39m     l2_reg_strength = \u001b[32m1.0\u001b[39m / (C * sw_sum)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/sklearn/utils/optimize.py:294\u001b[39m, in \u001b[36m_newton_cg\u001b[39m\u001b[34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn, verbose)\u001b[39m\n\u001b[32m    290\u001b[39m termcond = eta * maggrad\n\u001b[32m    292\u001b[39m \u001b[38;5;66;03m# Inner loop: solve the Newton update by conjugate gradient, to\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# avoid inverting the Hessian\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m xsupi = \u001b[43m_cg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfhess_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxinner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtermcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m alphak = \u001b[32m1.0\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m line_search:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/sklearn/utils/optimize.py:157\u001b[39m, in \u001b[36m_cg\u001b[39m\u001b[34m(fhess_p, fgrad, maxiter, tol, verbose)\u001b[39m\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    152\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Inner CG solver iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m stopped with\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    153\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    sum(|residuals|) <= tol: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.sum(np.abs(ri))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m <= \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    154\u001b[39m         )\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m Ap = \u001b[43mfhess_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsupi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# check curvature\u001b[39;00m\n\u001b[32m    159\u001b[39m curv = np.dot(psupi, Ap)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:752\u001b[39m, in \u001b[36mLinearModelLoss.gradient_hessian_product.<locals>.hessp\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    750\u001b[39m     ret[:n_features] = X.T @ (hX @ s[:n_features])\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m752\u001b[39m     ret[:n_features] = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    753\u001b[39m ret[:n_features] += l2_reg_strength * s[:n_features]\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit_intercept:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/numpy/linalg/_linalg.py:3001\u001b[39m, in \u001b[36mmulti_dot\u001b[39m\u001b[34m(arrays, out)\u001b[39m\n\u001b[32m   2999\u001b[39m \u001b[38;5;66;03m# _multi_dot_three is much faster than _multi_dot_matrix_chain_order\u001b[39;00m\n\u001b[32m   3000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m3\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3001\u001b[39m     result = \u001b[43m_multi_dot_three\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3002\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3003\u001b[39m     order = _multi_dot_matrix_chain_order(arrays)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/numpy/linalg/_linalg.py:3033\u001b[39m, in \u001b[36m_multi_dot_three\u001b[39m\u001b[34m(A, B, C, out)\u001b[39m\n\u001b[32m   3031\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dot(dot(A, B), C, out=out)\n\u001b[32m   3032\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3033\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# loops through each universe configuration loaded from universes.yaml \n",
    "# universes is a list of dictionaries, each containing model type and feature set, etc.\n",
    "# config is one universe dictionary\n",
    "\n",
    "for config in universes:\n",
    "    uid = config[\"id\"]\n",
    "    model_type = config[\"model\"]\n",
    "    feature_flag = config[\"feature_set\"]  # e.g., 'with_protected' or 'without_protected'\n",
    "\n",
    "    # Select the correct feature subset\n",
    "    if feature_flag == \"with_protected\":\n",
    "        X_train_used = X_train_f \n",
    "    elif feature_flag == \"without_protected\":\n",
    "        X_train_used = X_train_s\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown feature flag: {feature_flag}\")\n",
    "\n",
    "    # Train model\n",
    "    model = train_model(model_type, X_train_used, y_train)\n",
    "\n",
    "    # Store the trained model\n",
    "    trained_models[uid] = model\n",
    "\n",
    "    # Save model to file\n",
    "    model_filename = f\"./models/universe{uid}.joblib\"\n",
    "    dump(model, model_filename)\n",
    "\n",
    "    print(f\"Trained model for universe {uid}: {model_type} with {feature_flag} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea6157e",
   "metadata": {},
   "source": [
    "## 01 Logit Regression (w. protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm1 = LogisticRegression(penalty = None, solver = 'newton-cg', max_iter = 1000)\n",
    "glm1.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs1 = pd.DataFrame(X_train_f.columns, columns = ['var'])\n",
    "coefs1['coef'] = pd.DataFrame(glm1.coef_).transpose()\n",
    "\n",
    "# Build a DataFrame of feature names + their learned coefficients, to inspect which variables \n",
    "# (including protected attrs) the model weights most heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef186a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(glm1, './models/glm1.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f9880d",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "glmcv1 = cross_validate(estimator = glm1, \n",
    "                       X = X_train_f,\n",
    "                       y = y_train,\n",
    "                       cv = tscv,\n",
    "                       n_jobs = -1, # use all available cores\n",
    "                       scoring = score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV output\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(glmcv1)\n",
    "\n",
    "# Only keep test scores\n",
    "test_scores = results_df.filter(like='test_')\n",
    "\n",
    "# Summary statistics\n",
    "summary = test_scores.agg(['mean', 'std']).T\n",
    "summary.columns = ['mean', 'std']\n",
    "print(summary)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar chart of mean ± std\n",
    "summary.plot(kind='bar', y='mean', yerr='std', legend=False, capsize=4)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Cross-Validation Performance (mean ± std)\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9538551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV output\n",
    "\n",
    "test_scores.T.plot(marker='o')\n",
    "plt.title(\"Cross-Validation Scores per Fold\")\n",
    "plt.xlabel(\"Metric\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a68bde",
   "metadata": {},
   "source": [
    "## 02 Logit Regression (w/o protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm2 = LogisticRegression(penalty = None, solver = 'newton-cg', max_iter = 1000)\n",
    "glm2.fit(X_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs2 = pd.DataFrame(X_train_s.columns, columns = ['var'])\n",
    "coefs2['coef'] = pd.DataFrame(glm2.coef_).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(glm2, './models/glm2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9509612",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "k45 = 0.55 # Top 55% \n",
    "k30 = 0.30 # Top 30% \n",
    "k15 = 0.15 # Top 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm1_p = glm1.predict_proba(X_test_f)[:,1] # glm1\n",
    "\n",
    "# Generate the predicted probability of the positive class for each test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da52b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold45 = np.sort(glm1_p)[::-1][int(k45*len(glm1_p))]\n",
    "threshold30 = np.sort(glm1_p)[::-1][int(k30*len(glm1_p))]\n",
    "threshold15 = np.sort(glm1_p)[::-1][int(k15*len(glm1_p))] # threshold15 is the score above which only the top 15% of test samples lie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm1_c1 = glm1_p.copy()\n",
    "glm1_c1[glm1_c1 < threshold15] = 0\n",
    "glm1_c1[glm1_c1 >= threshold15] = 1\n",
    "\n",
    "# Create a binary classification vector where only the top 15% by predicted probability are labeled “1”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c693db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm1_c2 = glm1_p.copy()\n",
    "glm1_c2[glm1_c2 < threshold30] = 0\n",
    "glm1_c2[glm1_c2 >= threshold30] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae60ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm1_c3 = glm1_p.copy()\n",
    "glm1_c3[(glm1_c3 <= threshold30) | (glm1_c3 >= threshold15)] = 0\n",
    "glm1_c3[(glm1_c3 > threshold30) & (glm1_c3 < threshold15)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm1_c4 = glm1_p.copy()\n",
    "glm1_c4[(glm1_c4 <= threshold45) | (glm1_c4 >= threshold15)] = 0\n",
    "glm1_c4[(glm1_c4 > threshold45) & (glm1_c4 < threshold15)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a265d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm2_p = glm2.predict_proba(X_test_s)[:,1] # glm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold45 = np.sort(glm2_p)[::-1][int(k45*len(glm2_p))]\n",
    "threshold30 = np.sort(glm2_p)[::-1][int(k30*len(glm2_p))]\n",
    "threshold15 = np.sort(glm2_p)[::-1][int(k15*len(glm2_p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c13af",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm2_c1 = glm2_p.copy()\n",
    "glm2_c1[glm2_c1 < threshold15] = 0\n",
    "glm2_c1[glm2_c1 >= threshold15] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18663c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm2_c2 = glm2_p.copy()\n",
    "glm2_c2[glm2_c2 < threshold30] = 0\n",
    "glm2_c2[glm2_c2 >= threshold30] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm2_c3 = glm2_p.copy()\n",
    "glm2_c3[(glm2_c3 <= threshold30) | (glm2_c3 >= threshold15)] = 0\n",
    "glm2_c3[(glm2_c3 > threshold30) & (glm2_c3 < threshold15)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glm2_c4 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d561c",
   "metadata": {},
   "source": [
    "## Performance evaluation -> delete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce6795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c80d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for preds, label in zip(\n",
    "    [glm1_c1, glm1_c2, glm1_c3, glm1_c4],\n",
    "    [\"Top 15%\", \"Top 30%\", \"Middle 15-30%\", \"Middle 15-45%\"]\n",
    "):\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1  = f1_score(y_test, preds)\n",
    "    print(f\"{label:15s} → Accuracy: {acc:.3f},  F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802e105f",
   "metadata": {},
   "source": [
    "## Combine and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Build a single DataFrame side by side with:\n",
    "      - The true labels (‘y_test’)\n",
    "      - The raw predicted probabilities (‘glm1_p’)\n",
    "      - Each binary decision vector at different cutoffs (‘glm1_c1’, ‘glm1_c2’, ‘glm1_c3’).\n",
    "'''\n",
    "\n",
    "preds_test = pd.concat([pd.DataFrame(np.array(y_test), columns = ['y_test']),\n",
    "                         pd.DataFrame(glm1_p, columns = ['glm1_p']),\n",
    "                         pd.DataFrame(glm1_c1, columns = ['glm1_c1']),\n",
    "                         pd.DataFrame(glm1_c2, columns = ['glm1_c2']),\n",
    "                         pd.DataFrame(glm1_c3, columns = ['glm1_c3']),\n",
    "                         pd.DataFrame(glm1_c4, columns = ['glm1_c4']),\n",
    "                         pd.DataFrame(glm2_p, columns = ['glm2_p']),\n",
    "                         pd.DataFrame(glm2_c1, columns = ['glm2_c1']),\n",
    "                         pd.DataFrame(glm2_c2, columns = ['glm2_c2']),\n",
    "                         pd.DataFrame(glm2_c3, columns = ['glm2_c3'])],\n",
    "                        axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caba314",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test.to_csv('./output/preds_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac19281",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577241a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glm1 \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# Define your predictions\n",
    "threshold_preds = {\n",
    "    \"Top 15% (glm1_c1)\": glm1_c1,\n",
    "    \"Top 30% (glm1_c2)\": glm1_c2,\n",
    "    \"Between 15% and 30% (glm1_c3)\": glm1_c3,\n",
    "    \"Between 15% and 45% (glm1_c4)\": glm1_c4,\n",
    "}\n",
    "\n",
    "# Evaluate\n",
    "results = []\n",
    "\n",
    "for label, y_pred in threshold_preds.items():\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"Policy\": label,\n",
    "        \"TP\": tp,\n",
    "        \"FP\": fp,\n",
    "        \"TN\": tn,\n",
    "        \"FN\": fn,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1\n",
    "    })\n",
    "\n",
    "# Display as DataFrame\n",
    "df_threshold_metrics = pd.DataFrame(results)\n",
    "print(df_threshold_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2362a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glm2 \n",
    "\n",
    "# Define your predictions\n",
    "threshold_preds = {\n",
    "    \"Top 15% (glm2_c1)\": glm2_c1,\n",
    "    \"Top 30% (glm2_c2)\": glm2_c2,\n",
    "    \"Between 15% and 30% (glm1_c3)\": glm2_c3,\n",
    "}\n",
    "\n",
    "# Evaluate\n",
    "results = []\n",
    "\n",
    "for label, y_pred in threshold_preds.items():\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"Policy\": label,\n",
    "        \"TP\": tp,\n",
    "        \"FP\": fp,\n",
    "        \"TN\": tn,\n",
    "        \"FN\": fn,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1\n",
    "    })\n",
    "\n",
    "# Display as DataFrame\n",
    "df_threshold_metrics = pd.DataFrame(results)\n",
    "print(df_threshold_metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
