{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7bebcf4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3682bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When working in AI LRZ\n",
    "%cd ~/projects/cma_f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08327b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julia/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/Users/julia/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import make_scorer, confusion_matrix\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate # GroupKFold, GridSearchCV,\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from joblib import dump\n",
    "\n",
    "from utils import (\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9275fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load universe definitions from YAML\n",
    "import yaml\n",
    "\n",
    "with open(\"universes.yaml\") as f:\n",
    "    universes = yaml.safe_load(f)\n",
    "\n",
    "# Access by ID\n",
    "#universe_id = 12\n",
    "#config = next(u for u in universes if u[\"id\"] == universe_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298f2b2",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa524e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f = pd.read_csv(\"./output/X_train_f.csv\") # 2010 - 2014, w. protected attributes\n",
    "X_train_s = pd.read_csv(\"./output/X_train_s.csv\") # 2010 - 2014, w/o protected attributes\n",
    "y_train = pd.read_csv(\"./output/y_train.csv\").iloc[:,0]\n",
    "\n",
    "X_test_f = pd.read_csv(\"./output/X_test_f.csv\")\n",
    "X_test_s = pd.read_csv(\"./output/X_test_s.csv\")\n",
    "y_test = pd.read_csv(\"./output/y_test.csv\").iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d403690f",
   "metadata": {},
   "source": [
    "## Multiverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28fde7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_type, X, y):\n",
    "    if model_type == \"logreg\":\n",
    "        model = LogisticRegression(penalty=None, solver=\"newton-cg\", max_iter=1000, random_state=19)\n",
    "    elif model_type == \"penalized_logreg\":\n",
    "        model = LogisticRegression(penalty=\"l2\", C=1.0, solver=\"newton-cg\", max_iter=1000, random_state=19)\n",
    "    elif model_type == \"rf\":\n",
    "        model = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=19)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e83f5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test feature sets\n",
    "feature_sets_train = {\n",
    "    \"with_protected\": X_train_f,\n",
    "    \"without_protected\": X_train_s\n",
    "}\n",
    "feature_sets_test = {\n",
    "    \"with_protected\": X_test_f,\n",
    "    \"without_protected\": X_test_s\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0123b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds\n",
    "threshold_policies = {\n",
    "    \"top15\": 0.15,\n",
    "    \"top30\": 0.30\n",
    "}\n",
    "\n",
    "#    \"top45\": 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84fca6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group universes by (model_type, feature_flag)\n",
    "from collections import defaultdict\n",
    "universe_groups = defaultdict(list)\n",
    "for cfg in universes:\n",
    "    key = (cfg[\"model\"], cfg[\"feature_set\"])\n",
    "    universe_groups[key].append(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17513cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: logreg with with_protected features\n",
      "Predicted universe 1: logreg, with_protected, top15\n",
      "Predicted universe 2: logreg, with_protected, top30\n",
      "Training model: logreg with without_protected features\n",
      "Predicted universe 3: logreg, without_protected, top15\n",
      "Predicted universe 4: logreg, without_protected, top30\n",
      "Training model: penalized_logreg with with_protected features\n",
      "Predicted universe 5: penalized_logreg, with_protected, top15\n",
      "Predicted universe 6: penalized_logreg, with_protected, top30\n",
      "Training model: penalized_logreg with without_protected features\n",
      "Predicted universe 7: penalized_logreg, without_protected, top15\n",
      "Predicted universe 8: penalized_logreg, without_protected, top30\n",
      "Training model: rf with with_protected features\n",
      "Predicted universe 9: rf, with_protected, top15\n",
      "Predicted universe 10: rf, with_protected, top30\n",
      "Training model: rf with without_protected features\n",
      "Predicted universe 11: rf, without_protected, top15\n",
      "Predicted universe 12: rf, without_protected, top30\n"
     ]
    }
   ],
   "source": [
    "# Train one model per (model_type, feature_flag), then apply all thresholds\n",
    "\n",
    "predictions_by_universe = {}\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "for (model_type, feature_flag), cfgs in universe_groups.items():\n",
    "    print(f\"Training model: {model_type} with {feature_flag} features\")\n",
    "    X_train_used = feature_sets_train[feature_flag]\n",
    "    model = train_model(model_type, X_train_used, y_train)\n",
    "\n",
    "    # Save model\n",
    "    universe_id = f\"{model_type}_{feature_flag}\"\n",
    "    dump(model, f\"./models/{universe_id}.joblib\")\n",
    "\n",
    "    # Predict probabilities on test set\n",
    "    X_test_used = feature_sets_test[feature_flag]\n",
    "    probs = model.predict_proba(X_test_used)[:, 1]\n",
    "\n",
    "    for cfg in cfgs:\n",
    "        uid = cfg[\"id\"]\n",
    "        threshold_key = cfg[\"threshold_policy\"]\n",
    "        k = threshold_policies[threshold_key]\n",
    "        threshold_value = np.sort(probs)[::-1][int(k * len(probs))]\n",
    "        binary_preds = (probs >= threshold_value).astype(int)\n",
    "        predictions_by_universe[uid] = binary_preds\n",
    "        print(f\"Predicted universe {uid}: {model_type}, {feature_flag}, {threshold_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0315510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results into a DataFrame for inspection/saving\n",
    "y_test_array = np.array(y_test).reshape(-1, 1)\n",
    "y_df = pd.DataFrame(y_test_array, columns=[\"y_test\"])\n",
    "\n",
    "all_preds = []\n",
    "for uid in sorted(predictions_by_universe):\n",
    "    col_name = f\"preds_u{uid}\"\n",
    "    col_data = pd.DataFrame(predictions_by_universe[uid], columns=[col_name])\n",
    "    all_preds.append(col_data)\n",
    "\n",
    "preds_test = pd.concat([y_df] + all_preds, axis=1)\n",
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "preds_test.to_csv(\"./output/preds_test.csv\", index=False)\n",
    "\n",
    "#print(\"Saved combined predictions to ./output/preds_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c5ed6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/6qcvyjh51cg86vrxn3xs8c_40000gn/T/ipykernel_53324/2427680122.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  universe_df_escaped = universe_df.applymap(escape_latex_str)\n"
     ]
    }
   ],
   "source": [
    "# Create LaTeX summary table for universes\n",
    "def escape_latex_str(val):\n",
    "    return str(val).replace('_', '\\\\_')\n",
    "\n",
    "universe_df = pd.DataFrame(universes)\n",
    "\n",
    "# Rename and reorder columns\n",
    "universe_df = universe_df.rename(columns={\n",
    "    \"feature_set\": \"feature set\",\n",
    "    \"threshold_policy\": \"threshold\"\n",
    "})\n",
    "universe_df = universe_df[[\"id\", \"model\", \"feature set\", \"threshold\"]]\n",
    "\n",
    "universe_df_escaped = universe_df.applymap(escape_latex_str)\n",
    "\n",
    "latex_table = universe_df_escaped.to_latex(\n",
    "    index=False,\n",
    "    caption=\"Universe configuration overview\",\n",
    "    label=\"tab:universe_summary\",\n",
    "    escape=False\n",
    ")\n",
    "\n",
    "with open(\"./output/universe_summary.tex\", \"w\") as f:\n",
    "    f.write(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac19281",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e22ab764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect confusion matrices for all universes\n",
    "confusion_matrices = []\n",
    "\n",
    "for uid, preds in predictions_by_universe.items():\n",
    "    cm = confusion_matrix(y_test, preds, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    confusion_matrices.append({\n",
    "        \"id\": uid,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"tp\": tp,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6241cff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id     tn     fp    fn    tp  accuracy  precision    recall        f1\n",
      "0    1  69037   9165  7216  4292  0.817401   0.318942  0.372958  0.343841\n",
      "1    2  58476  19726  4320  7188  0.731959   0.267073  0.624609  0.374161\n",
      "2    3  69056   9146  7197  4311  0.817824   0.320354  0.374609  0.345364\n",
      "3    4  58510  19692  4286  7222  0.732717   0.268336  0.627563  0.375930\n",
      "4    5  69034   9168  7219  4289  0.817334   0.318719  0.372697  0.343601\n",
      "5    6  58477  19725  4319  7189  0.731981   0.267110  0.624696  0.374213\n",
      "6    7  69057   9145  7196  4312  0.817846   0.320428  0.374696  0.345444\n",
      "7    8  58509  19693  4287  7221  0.732694   0.268299  0.627477  0.375878\n",
      "8    9  67976  10226  7127  4381  0.806566   0.299925  0.380692  0.335516\n",
      "9   10  57639  20563  4473  7035  0.720923   0.254910  0.611314  0.359791\n",
      "10  11  68491   9711  7376  4132  0.809531   0.298490  0.359055  0.325983\n",
      "11  12  57230  20972  4459  7049  0.716520   0.251561  0.612530  0.356650\n"
     ]
    }
   ],
   "source": [
    "confusion_df = pd.DataFrame(confusion_matrices)\n",
    "confusion_df = confusion_df.sort_values(\"id\")\n",
    "print(confusion_df)\n",
    "#confusion_df.to_csv(\"./output/confusion_matrices.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
