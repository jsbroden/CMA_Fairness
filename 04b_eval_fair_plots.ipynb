{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53d61258",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dd9eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from matplotlib.lines import Line2D\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5836f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, make_scorer, roc_curve, auc, precision_recall_curve, classification_report, confusion_matrix, accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139354ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import aif_test, aif_plot, aif_plot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da7efa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f = pd.read_csv(\"./output/X_train_f.csv\")\n",
    "X_train_s = pd.read_csv(\"./output/X_train_s.csv\")\n",
    "\n",
    "X_test_f = pd.read_csv(\"./output/X_test_f.csv\")\n",
    "X_test_s = pd.read_csv(\"./output/X_test_s.csv\")\n",
    "y_test = pd.read_csv(\"./output/y_test.csv\")\n",
    "\n",
    "preds_test = pd.read_csv(\"./output/preds_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4636890c",
   "metadata": {},
   "source": [
    "# 01 Plot risk scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_test = pd.read_csv(\"./output/comb_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64696279",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = comb_test, x = 'glm1_p', kde = True, stat = 'density', common_norm = False, element = 'step')\n",
    "#sns.histplot(data = comb_test, x = 'glm2b_p', kde = True, stat = 'density', common_norm = False, element = 'step', color = 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(font_scale = 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6869e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold30 = np.sort(comb_test.glm1_p)[::-1][int(0.30*len(comb_test.glm1_p))]\n",
    "threshold15 = np.sort(comb_test.glm1_p)[::-1][int(0.15*len(comb_test.glm1_p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda8311",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.histplot(data = comb_test, x = 'glm1_p', hue = 'frau1', kde = True, stat = 'density', common_norm = False, element = 'step')\n",
    "sns_plot.set(xlabel = 'Risk Score')\n",
    "sns_plot.legend(title = '', labels = ['Female', 'Male'])\n",
    "sns_plot.axvline(threshold30, color='k', linestyle='dashed')\n",
    "sns_plot.axvline(threshold15, color='k', linestyle='dotted')\n",
    "sns_plot.text(threshold15 - 0.02, 5.7, 'P1a')\n",
    "sns_plot.text(threshold30 - 0.02, 5.7, 'P1b')\n",
    "sns_plot.figure.savefig('glm1_p_sex.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.histplot(data = comb_test, x = 'glm1_p', hue = 'nongerman', kde = True, stat = 'density', common_norm = False, element = 'step')\n",
    "sns_plot.set(xlabel = 'Risk Score')\n",
    "sns_plot.legend(title = '', labels = ['Non-German', 'German'])\n",
    "sns_plot.axvline(threshold30, color='k', linestyle='dashed')\n",
    "sns_plot.axvline(threshold15, color='k', linestyle='dotted')\n",
    "sns_plot.text(threshold15 - 0.02, 6.2, 'P1a')\n",
    "sns_plot.text(threshold30 - 0.02, 6.2, 'P1b')\n",
    "sns_plot.figure.savefig('glm1_p_ger.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e86b0",
   "metadata": {},
   "source": [
    "# 02 Performance and Fairness vs. Threshold Plots\n",
    "# https://nbviewer.jupyter.org/github/IBM/AIF360/blob/master/examples/tutorial_medical_expenditure.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a85e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = pd.concat([y_test, X_test_f], axis = 1)\n",
    "\n",
    "label_test.loc[label_test['maxdeutsch.Missing.'] == 1, 'maxdeutsch1'] = np.nan\n",
    "preds_test.loc[label_test['maxdeutsch.Missing.'] == 1, 'y_test'] = np.nan\n",
    "\n",
    "label_test = label_test.dropna()\n",
    "preds_test = preds_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56155b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over models (w/o protected attributes) and create plots\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d2930",
   "metadata": {},
   "source": [
    "# 03 Fairness vs Accuracy Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_group = pd.read_csv(\"./output/f1_group.csv\")\n",
    "f1_group = f1_group.loc[(f1_group['pop'] != 'Overall')]\n",
    "acc_group = pd.read_csv(\"./output/acc_group.csv\")\n",
    "acc_group = acc_group.loc[(acc_group['pop'] != 'Overall')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e860aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness1 = pd.read_csv(\"./output/test_fairness1.csv\")\n",
    "fairness1 = fairness1.iloc[1: , :]\n",
    "cond_fair1 = pd.read_csv(\"./output/test_cond_fairness1.csv\")\n",
    "cond_fair1 = cond_fair1.iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee5388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness1[['method', 'Type', 'Cutoff']] = fairness1['Model'].str.split(pat='(\\d)', n=1, expand=True) # Split up cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness = fairness1 #.append([fairness1b, fairness2, fairness2b]) # Append\n",
    "fairness = fairness.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca862ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness['Cutoff'] = fairness['Cutoff'].str.replace(r'_', '') # Clean up\n",
    "fairness = fairness.loc[(fairness['Cutoff'] == 'c1') | (fairness['Cutoff'] == 'c2')]\n",
    "fairness['method'] = fairness['method'].astype('category')\n",
    "fairness['method'] = fairness['method'].cat.rename_categories({'glm': 'LR', \n",
    "                                                               'net': 'PLR', \n",
    "                                                               'rf': 'RF', \n",
    "                                                               'gbm': 'GBM'})\n",
    "fairness = fairness.drop(columns = ['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d578a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness = fairness.melt(id_vars=['method', 'Type', 'Cutoff'], var_name = 'pop') # Long format\n",
    "fairness['pop'] = fairness['pop'].astype('category')\n",
    "fairness['pop'] = fairness['pop'].cat.rename_categories({'Parity Diff. (Female)': 'Female', \n",
    "                                                         'Parity Diff. (Non-German)': 'Non-German', \n",
    "                                                         'Parity Diff. (Non-German-Male)': 'Non-Ger. M', \n",
    "                                                         'Parity Diff. (Non-German-Female)': 'Non-Ger. F'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa2bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness = fairness.rename(columns={'value': 'Parity Diff.'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab64db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added from me\n",
    "\n",
    "# Ensure 'Type' is the same dtype in both DataFrames\n",
    "fairness['Type'] = fairness['Type'].astype(str)\n",
    "f1_group['Type'] = f1_group['Type'].astype(str)\n",
    "\n",
    "acc_group['Type'] = acc_group['Type'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1d9121",
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_f1 = pd.merge(fairness, f1_group, on=['pop', 'method', 'Type', 'Cutoff']) # Merge\n",
    "fair_acc = pd.merge(fairness, acc_group, on=['pop', 'method', 'Type', 'Cutoff'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a138dfc2",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.2)\n",
    "\n",
    "sns.scatterplot(x = \"Parity Diff.\", y = \"value\", hue = 'method', data = fair_f1)\n",
    "sns.scatterplot(x = \"Parity Diff.\", y = \"value\", hue = 'pop', data = fair_f1)\n",
    "sns.scatterplot(x = \"Parity Diff.\", y = \"value\", hue = 'Cutoff', data = fair_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939dbfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8.5, 7))\n",
    "ax = sns.scatterplot(data = fair_f1, x = \"Parity Diff.\", y = \"value\", hue = 'Cutoff', style = 'pop', palette = \"muted\", s = 90, alpha = 0.85)\n",
    "ax.set_xlabel(\"Parity Diff.\")\n",
    "ax.set_ylabel(\"F1 Score\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles, ['', 'Policy 1a', 'Policy 1b', '', 'Female', 'Non-German', 'Non-Ger. M', 'Non-Ger. F'], bbox_to_anchor = (1, 0.8), loc = 2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/fair_f1', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73264e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(data = fair_f1, x = \"Parity Diff.\", y = \"value\", hue = 'Cutoff', palette = \"muted\", xlim = [-0.225, 0.1], ylim = [0.1, 0.44], height = 7, ratio = 5)\n",
    "g.plot_joint(sns.scatterplot, style = 'pop', data = fair_f1, s = 75, alpha = 0.8)\n",
    "g.plot_marginals(sns.kdeplot, fill = True, alpha = 0.15, bw_adjust = .9, linewidth = 1)\n",
    "g.set_axis_labels('Parity Diff.', 'F1 Score')\n",
    "g.ax_joint.legend_._visible = False\n",
    "handles, labels = g.ax_joint.get_legend_handles_labels()\n",
    "g.fig.legend(handles = handles, labels = ['', 'Policy 1a', 'Policy 1b', '', 'Female', 'Non-German', 'Non-Ger. M', 'Non-Ger. F'], bbox_to_anchor = (0.935, 0.675), loc = 2)\n",
    "g.savefig('./output/fair_f1_joint', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = \"Parity Diff.\", y = \"value\", hue = 'method', data = fair_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3207d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = \"Parity Diff.\", y = \"value\", hue = 'pop', data = fair_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = \"Parity Diff.\", y = \"value\", hue = 'Cutoff', data = fair_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ede258",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8.5, 7))\n",
    "ax = sns.scatterplot(data = fair_acc, x = \"Parity Diff.\", y = \"value\", hue = 'Cutoff', style = 'pop', palette = \"muted\", s = 90, alpha = 0.85)\n",
    "ax.set_xlabel(\"Parity Diff.\")\n",
    "ax.set_ylabel(\"Bal. Accuracy\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles, ['', 'Policy 1a', 'Policy 1b', '', 'Female', 'Non-German', 'Non-Ger. M', 'Non-Ger. F'], bbox_to_anchor = (1, 0.8), loc = 2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/fair_acc', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(data = fair_acc, x = \"Parity Diff.\", y = \"value\", hue = 'Cutoff', palette = \"muted\", xlim = [-0.225, 0.1], ylim = [0.485, 0.715], height = 7, ratio = 5)\n",
    "g.plot_joint(sns.scatterplot, style = 'pop', data = fair_f1, s = 75, alpha = 0.8)\n",
    "g.plot_marginals(sns.kdeplot, fill = True, alpha = 0.15, bw_adjust = .9, linewidth = 1)\n",
    "g.set_axis_labels('Parity Diff.', 'Bal. Accuracy')\n",
    "g.ax_joint.legend_._visible = False\n",
    "handles, labels = g.ax_joint.get_legend_handles_labels()\n",
    "g.fig.legend(handles = handles, labels = ['', 'Policy 1a', 'Policy 1b', '', 'Female', 'Non-German', 'Non-Ger. M', 'Non-Ger. F'], bbox_to_anchor = (0.935, 0.675), loc = 2)\n",
    "g.savefig('./output/fair_acc_joint', dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
