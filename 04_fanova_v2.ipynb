{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67561337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70fab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/all_universe_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Mark each prediction as ambiguous\n",
    "#df['is_ambiguous'] = df['pred_set'].apply(lambda labels: 1 if len(labels) > 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e98a4",
   "metadata": {},
   "source": [
    "for CP threshold policy no difference, is it double in this data frame? Could this cause problems with fanova?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a795fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df['pred_set'] = df['pred_set'].apply(\n",
    "    lambda x: literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "df['is_ambiguous'] = df['pred_set'].apply(lambda preds: 1 if len(preds) > 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5456d2c",
   "metadata": {},
   "source": [
    "# Melt the subgroup flags into one column so you can group by them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f44fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of binary subgroup columns\n",
    "subgroup_cols = ['frau1', 'nongerman', 'nongerman_male', 'nongerman_female']\n",
    "\n",
    "# Melt to long format: one row per (row, subgroup) where value == 1\n",
    "df_long = df.melt(\n",
    "    id_vars=['UniverseID', 'feature_set', 'model', 'is_ambiguous'], #'threshold_policy'\n",
    "    value_vars=subgroup_cols,\n",
    "    var_name='subgroup',\n",
    "    value_name='is_member'\n",
    ")\n",
    "\n",
    "# Filter to keep only the subgroup memberships (i.e., rows where the person is in that group)\n",
    "df_long = df_long[df_long['is_member'] == 1]\n",
    "\n",
    "# in subgroup column it says \"other 9%\", for what does it stand? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f452b",
   "metadata": {},
   "source": [
    "# Compute the fraction of ambiguous predictions per (universe, subgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e1fc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['UniverseID', 'feature_set', 'model', 'subgroup'] #'threshold_policy',\n",
    "fractions = df_long.groupby(group_cols)['is_ambiguous'].mean().reset_index()\n",
    "fractions.rename(columns={'is_ambiguous': 'ambiguity_fraction'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6276f69",
   "metadata": {},
   "source": [
    "ToDo: fractions has 12 universes, but only 6 are actually different because of CP\n",
    "- Do I need to include overall in subgroups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "597cf19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows where UniverseID is an odd number\n",
    "unique_universes = fractions[fractions['UniverseID'] % 2 == 1].reset_index(drop=True)\n",
    "fractions = unique_universes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a67c1",
   "metadata": {},
   "source": [
    "# For each universe, compute the maximum pairwise difference in ambiguity fraction between subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c158d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute disparity per universe = max - min ambiguity_fraction across subgroups\n",
    "disparity_df = fractions.groupby(['feature_set', 'model'])['ambiguity_fraction']\\\n",
    "                        .agg(lambda x: x.max() - x.min())\\\n",
    "                        .reset_index(name='ambiguity_disparity')\n",
    "\n",
    "## add universe id \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cefae4",
   "metadata": {},
   "source": [
    "# fANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61602ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ConfigSpace import ConfigurationSpace, CategoricalHyperparameter\n",
    "from fanova import fANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6201a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ConfigSpace with categorical decision options\n",
    "cs = ConfigurationSpace()\n",
    "for col in ['feature_set', 'model']: # 'threshold_policy'\n",
    "    choices = sorted(disparity_df[col].unique().tolist())\n",
    "    cs.add(CategoricalHyperparameter(col, choices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47736203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical values as integer codes\n",
    "#encoders = {\n",
    "#    col: {val: idx for idx, val in enumerate(sorted(disparity_df[col].unique()))}\n",
    "#    for col in ['feature_set', 'model', 'threshold_policy']\n",
    "#}\n",
    "#\n",
    "#X = np.vstack([\n",
    "#    disparity_df['feature_set'].map(encoders['feature_set']),\n",
    "#    disparity_df['model'].map(encoders['model']),\n",
    "#    disparity_df['threshold_policy'].map(encoders['threshold_policy']),\n",
    "#]).T\n",
    "#\n",
    "#Y = disparity_df['ambiguity_disparity'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7395085",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_order = [hp.name for hp in cs.values()]\n",
    "X = disparity_df[hp_order].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a37cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map categorical values to integers (same as before)\n",
    "for col in hp_order:\n",
    "    encoder = {val: i for i, val in enumerate(sorted(disparity_df[col].unique()))}\n",
    "    X[col] = X[col].map(encoder)\n",
    "\n",
    "X_array = X.to_numpy(dtype=float)  # ensure float dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1502d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = disparity_df['ambiguity_disparity'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e20044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fanova.fanova.fANOVA:Note that fANOVA expects data to be ordered like the return of ConfigSpace's 'get_hyperparameters'-method. We recommend to use labeled pandas dataframes to avoid any problems.\n"
     ]
    }
   ],
   "source": [
    "# Run fANOVA\n",
    "fanova = fANOVA(X_array, Y, config_space=cs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a0d266a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get individual importance scores\u001b[39;00m\n\u001b[32m      2\u001b[39m importance = {\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeature_set\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mfanova\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantify_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mindividual importance\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: fanova.quantify_importance((\u001b[32m1\u001b[39m,))[\u001b[33m'\u001b[39m\u001b[33mindividual importance\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m#'threshold_policy': fanova.quantify_importance((2,))['individual importance'],\u001b[39;00m\n\u001b[32m      6\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/fanova/fanova.py:343\u001b[39m, in \u001b[36mfANOVA.quantify_importance\u001b[39m\u001b[34m(self, dims)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(non_zero_idx[\u001b[32m0\u001b[39m]) == \u001b[32m0\u001b[39m:\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mEncountered zero total variance in all trees.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m fractions_total = np.array(\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mV_U_total\u001b[49m\u001b[43m[\u001b[49m\u001b[43msub_dims\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrees_total_variance\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m                            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnon_zero_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m    345\u001b[39m fractions_individual = np.array([\u001b[38;5;28mself\u001b[39m.V_U_individual[sub_dims][t] / \u001b[38;5;28mself\u001b[39m.trees_total_variance[t]\n\u001b[32m    346\u001b[39m                                  \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m non_zero_idx[\u001b[32m0\u001b[39m]])\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(dims[\u001b[32m0\u001b[39m]) == \u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CMA_Fairness/cma_f/lib/python3.11/site-packages/fanova/fanova.py:343\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(non_zero_idx[\u001b[32m0\u001b[39m]) == \u001b[32m0\u001b[39m:\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mEncountered zero total variance in all trees.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m fractions_total = np.array([\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mV_U_total\u001b[49m\u001b[43m[\u001b[49m\u001b[43msub_dims\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m / \u001b[38;5;28mself\u001b[39m.trees_total_variance[t]\n\u001b[32m    344\u001b[39m                             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m non_zero_idx[\u001b[32m0\u001b[39m]])\n\u001b[32m    345\u001b[39m fractions_individual = np.array([\u001b[38;5;28mself\u001b[39m.V_U_individual[sub_dims][t] / \u001b[38;5;28mself\u001b[39m.trees_total_variance[t]\n\u001b[32m    346\u001b[39m                                  \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m non_zero_idx[\u001b[32m0\u001b[39m]])\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(dims[\u001b[32m0\u001b[39m]) == \u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Get individual importance scores\n",
    "importance = {\n",
    "    'feature_set': fanova.quantify_importance((0,))['individual importance'],\n",
    "    'model': fanova.quantify_importance((1,))['individual importance'],\n",
    "    #'threshold_policy': fanova.quantify_importance((2,))['individual importance'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd082411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error computing importance: list index out of range\n"
     ]
    }
   ],
   "source": [
    "# Get individual importance scores\n",
    "# Check for valid dimension indices and handle empty or invalid results\n",
    "try:\n",
    "    importance = {\n",
    "        'feature_set': fanova.quantify_importance((0,))['individual importance'],\n",
    "        'model': fanova.quantify_importance((1,))['individual importance'],\n",
    "        # 'threshold_policy': fanova.quantify_importance((2,))['individual importance'],\n",
    "    }\n",
    "except (IndexError, KeyError, RuntimeError) as e:\n",
    "    print(f\"Error computing importance: {e}\")\n",
    "    importance = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed65a47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dimensions in V_U_total:\n",
      "[(0,), (1,)]\n",
      "Total variance per tree (non-zero indices):\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "# Inspect which dimensions are available in fANOVA\n",
    "print(\"Available dimensions in V_U_total:\")\n",
    "print(list(fanova.V_U_total.keys()))\n",
    "\n",
    "print(\"Total variance per tree (non-zero indices):\")\n",
    "print([i for i, v in enumerate(fanova.trees_total_variance) if v != 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a1488ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dimensions in V_U_total: [(0,), (1,)]\n",
      "Non-zero total variances: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Error computing importance: list index out of range\n"
     ]
    }
   ],
   "source": [
    "# Get individual importance scores with debug output\n",
    "try:\n",
    "    print(\"Available dimensions in V_U_total:\", list(fanova.V_U_total.keys()))\n",
    "    print(\"Non-zero total variances:\", [i for i, v in enumerate(fanova.trees_total_variance) if v != 0])\n",
    "\n",
    "    importance = {\n",
    "        'feature_set': fanova.quantify_importance((0,))['individual importance'],\n",
    "        'model': fanova.quantify_importance((1,))['individual importance'],\n",
    "    }\n",
    "except (IndexError, KeyError, RuntimeError) as e:\n",
    "    print(f\"Error computing importance: {e}\")\n",
    "    importance = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a9696b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length V_U_total(0,) = 0\n",
      "Length trees_total_variance = 16\n",
      "Exception during inspection or importance computation: list index out of range\n"
     ]
    }
   ],
   "source": [
    "# Deep inspection of V_U_total and trees_total_variance\n",
    "sub_dims = (0,)\n",
    "try:\n",
    "    print(f\"Length V_U_total{sub_dims} =\", len(fanova.V_U_total[sub_dims]))\n",
    "    print(f\"Length trees_total_variance =\", len(fanova.trees_total_variance))\n",
    "\n",
    "    for i in range(len(fanova.V_U_total[sub_dims])):\n",
    "        print(f\"Tree {i}: V_U_total = {fanova.V_U_total[sub_dims][i]}, Total variance = {fanova.trees_total_variance[i]}\")\n",
    "\n",
    "    # Try quantifying importance\n",
    "    importance = fanova.quantify_importance(sub_dims)['individual importance']\n",
    "    print(\"Importance computed:\", importance)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Exception during inspection or importance computation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b114096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No usable variance data for dimension (0,). Skipping.\n"
     ]
    }
   ],
   "source": [
    "# Check for valid variance data before computing importance\n",
    "sub_dims = (0,)\n",
    "\n",
    "if sub_dims in fanova.V_U_total and len(fanova.V_U_total[sub_dims]) > 0:\n",
    "    try:\n",
    "        importance = fanova.quantify_importance(sub_dims)['individual importance']\n",
    "        print(\"Importance computed:\", importance)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception during importance computation: {e}\")\n",
    "        importance = None\n",
    "else:\n",
    "    print(f\"No usable variance data for dimension {sub_dims}. Skipping.\")\n",
    "    importance = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88b35618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No usable variance data for dimension (0,) (feature_set). Skipping.\n",
      "No usable variance data for dimension (1,) (model). Skipping.\n"
     ]
    }
   ],
   "source": [
    "# Safely compute importance for all expected dimensions\n",
    "importance = {}\n",
    "for i, name in enumerate(['feature_set', 'model']):\n",
    "    sub_dims = (i,)\n",
    "    if sub_dims in fanova.V_U_total and len(fanova.V_U_total[sub_dims]) > 0:\n",
    "        try:\n",
    "            imp = fanova.quantify_importance(sub_dims)['individual importance']\n",
    "            importance[name] = imp\n",
    "            print(f\"Importance for {name}: {imp}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Exception during importance computation for {name}: {e}\")\n",
    "            importance[name] = None\n",
    "    else:\n",
    "        print(f\"No usable variance data for dimension {sub_dims} ({name}). Skipping.\")\n",
    "        importance[name] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ab7c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All entries in V_U_total:\n",
      "  (0,): length = 0\n",
      "  (1,): length = 0\n",
      "Total number of trees with non-zero variance: 16\n"
     ]
    }
   ],
   "source": [
    "# Investigate full contents of V_U_total and trees_total_variance\n",
    "print(\"All entries in V_U_total:\")\n",
    "for dims, values in fanova.V_U_total.items():\n",
    "    print(f\"  {dims}: length = {len(values)}\")\n",
    "\n",
    "print(\"Total number of trees with non-zero variance:\", sum(v != 0 for v in fanova.trees_total_variance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ade6dc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: variance = 0.25\n",
      "Feature 1: variance = 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Inspect raw input variance to understand why fANOVA produced no usable importance values\n",
    "\n",
    "# X should be the input matrix passed to fANOVA\n",
    "variances = np.var(X, axis=0)\n",
    "for i, v in enumerate(variances):\n",
    "    print(f\"Feature {i}: variance = {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa8ed03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes in fanova: ['V_U_individual', 'V_U_total', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_dict', '_fANOVA__compute_marginals', 'all_midpoints', 'all_sizes', 'cs', 'cs_params', 'cutoffs', 'get_most_important_pairwise_marginals', 'get_triple_marginals', 'logger', 'marginal_mean_variance_for_values', 'n_dims', 'n_trees', 'percentiles', 'quantify_importance', 'set_cutoffs', 'the_forest', 'trees_total_variance', 'trees_total_variances', 'trees_variance_fractions', 'variance_dict']\n",
      "Error during variance recomputation: 'fANOVA' object has no attribute '_compute_variances'\n"
     ]
    }
   ],
   "source": [
    "# Check available attributes\n",
    "print(\"Available attributes in fanova:\", dir(fanova))\n",
    "\n",
    "# Fallback if `n_dimensions` is not available\n",
    "if hasattr(fanova, 'config_space'):\n",
    "    print(\"Config space dimensions:\", len(fanova.config_space.get_hyperparameters()))\n",
    "\n",
    "# Attempt recomputation (alternative safe method)\n",
    "try:\n",
    "    fanova._compute_variances()  # Internal method that populates V_U_total\n",
    "    print(\"Recomputation of variances triggered.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during variance recomputation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "127817c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error inspecting trees in the forest: 'fanova_forest' object has no attribute 'trees'\n"
     ]
    }
   ],
   "source": [
    "# Try inspecting trees from the_forest assuming it's an object with accessible attribute\n",
    "try:\n",
    "    trees = fanova.the_forest.trees\n",
    "    print(f\"Number of trees in the forest: {len(trees)}\")\n",
    "    for i, tree in enumerate(trees[:3]):\n",
    "        print(f\"Tree {i} type: {type(tree)}\")\n",
    "        print(f\"Tree {i} attributes: {dir(tree)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inspecting trees in the forest: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "effd3218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while accessing members of fanova.the_forest: descriptor '__dict__' for 'fanova_forest_prototype' objects doesn't apply to a 'fanova_forest' object\n"
     ]
    }
   ],
   "source": [
    "# Use safe access method to probe attributes\n",
    "from inspect import getmembers\n",
    "\n",
    "# Try accessing all non-method members safely\n",
    "try:\n",
    "    members = getmembers(fanova.the_forest, lambda a: not callable(a))\n",
    "    for name, value in members:\n",
    "        if not name.startswith('__'):\n",
    "            if isinstance(value, list):\n",
    "                print(f\"{name}: list of length {len(value)}\")\n",
    "            elif hasattr(value, '__len__'):\n",
    "                print(f\"{name}: len = {len(value)}\")\n",
    "            else:\n",
    "                print(f\"{name}: type = {type(value)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while accessing members of fanova.the_forest: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d8cbf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually try to access attributes that may hold the trees\n",
    "possible_attrs = [\n",
    "    'rf', 'forest', '_forest', 'estimators_', 'base_forest', 'wrapped_forest', 'model_forest', 'raw_forest'\n",
    "]\n",
    "\n",
    "for attr in possible_attrs:\n",
    "    try:\n",
    "        value = getattr(fanova.the_forest, attr)\n",
    "        print(f\"{attr}: type={type(value)}, len={len(value) if hasattr(value, '__len__') else 'N/A'}\")\n",
    "    except AttributeError:\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"{attr}: error accessing attribute: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c7c8337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fanova.the_forest representation:\n",
      "<pyrfr.regression.fanova_forest; proxy of <Swig Object of type 'rfr::forests::fANOVA_forest< binary_rss_split_t,double,double,unsigned int,std::default_random_engine > *' at 0x152aa3ea0> >\n"
     ]
    }
   ],
   "source": [
    "# Print the string representation of the forest object to look for clues\n",
    "print(\"fanova.the_forest representation:\")\n",
    "print(fanova.the_forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12442da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirmed: fanova.the_forest is a pyrfr fanova_forest instance.\n",
      "Number of trees: 16\n",
      "Error accessing pyrfr forest methods: 'fanova_forest' object has no attribute 'num_features'\n"
     ]
    }
   ],
   "source": [
    "# Try accessing pyrfr wrapper if available\n",
    "try:\n",
    "    import pyrfr\n",
    "    if isinstance(fanova.the_forest, pyrfr.regression.fanova_forest):\n",
    "        print(\"Confirmed: fanova.the_forest is a pyrfr fanova_forest instance.\")\n",
    "        print(\"Number of trees:\", fanova.the_forest.num_trees())\n",
    "        print(\"Number of dimensions:\", fanova.the_forest.num_features())\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing pyrfr forest methods: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229813f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"fANOVA results (variance explained in ambiguity disparity):\")\n",
    "for key, val in importance.items():\n",
    "    print(f\"  {key}: {val * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0221b07d",
   "metadata": {},
   "source": [
    "# fANOVA v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "766027a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "if not hasattr(np, 'float'):\n",
    "    np.float = float  # Patch for fanova compatibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94a33d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build ConfigSpace and add hyperparameters\n",
    "from ConfigSpace import ConfigurationSpace, CategoricalHyperparameter\n",
    "\n",
    "cs = ConfigurationSpace()\n",
    "cs.add(\n",
    "    CategoricalHyperparameter(\"feature_set\", sorted(disparity_df[\"feature_set\"].unique())),\n",
    "    CategoricalHyperparameter(\"model\", sorted(disparity_df[\"model\"].unique())),\n",
    "    #CategoricalHyperparameter(\"threshold_policy\", sorted(disparity_df[\"threshold_policy\"].unique()))\n",
    ")\n",
    "\n",
    "# Step 2: Get correct hyperparameter order\n",
    "hp_order = [hp.name for hp in list(cs.values())]\n",
    "\n",
    "# Step 3: Encode categorical variables using consistent mapping\n",
    "X_df = disparity_df[hp_order].copy()\n",
    "for col in hp_order:\n",
    "    encoder = {val: i for i, val in enumerate(sorted(X_df[col].unique()))}\n",
    "    X_df[col] = X_df[col].map(encoder)\n",
    "X_df = X_df.astype(float)\n",
    "\n",
    "# Step 4: Now pass this labeled DataFrame directly to fANOVA\n",
    "from fanova import fANOVA\n",
    "\n",
    "Y = disparity_df[\"ambiguity_disparity\"].to_numpy()\n",
    "fanova = fANOVA(X_df, Y, config_space=cs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d098efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not compute importance for feature_set: 'SwigPyObject' object has no attribute 'mean'\n",
      "Could not compute importance for model: 'SwigPyObject' object has no attribute 'mean'\n",
      "fANOVA: Individual variance explained per decision factor (%):\n",
      "Empty DataFrame\n",
      "Columns: [individual importance]\n",
      "Index: []\n",
      "swig/python detected a memory leak of type 'rfr::util::weighted_running_statistics< double > *', no destructor found.\n",
      "swig/python detected a memory leak of type 'rfr::util::weighted_running_statistics< double > *', no destructor found.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract hyperparameters in correct order (no deprecated method)\n",
    "hp_list = list(cs.values())\n",
    "\n",
    "importance_scores = {}\n",
    "\n",
    "# Step 2: Loop through in order and extract individual importance scores\n",
    "for i, hp in enumerate(hp_list):\n",
    "    try:\n",
    "        result = fanova.quantify_importance((i,))\n",
    "        importance_scores[hp.name] = result[\"individual importance\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Could not compute importance for {hp.name}: {e}\")\n",
    "\n",
    "# Step 3: Format and display\n",
    "importance_df = pd.DataFrame.from_dict(\n",
    "    importance_scores, orient=\"index\", columns=[\"individual importance\"]\n",
    ")\n",
    "importance_df.sort_values(\"individual importance\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"fANOVA: Individual variance explained per decision factor (%):\")\n",
    "print((importance_df * 100).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fe21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(\"Var(Y):\", np.var(Y))\n",
    "# extremly small variance, so not much to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4bb747",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape:\", X_df.shape)\n",
    "print(\"Unique values per column:\")\n",
    "print(X_df.nunique())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
