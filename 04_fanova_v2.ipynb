{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67561337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70fab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/all_universe_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Mark each prediction as ambiguous\n",
    "#df['is_ambiguous'] = df['pred_set'].apply(lambda labels: 1 if len(labels) > 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a795fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df['pred_set'] = df['pred_set'].apply(\n",
    "    lambda x: literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "df['is_ambiguous'] = df['pred_set'].apply(lambda preds: 1 if len(preds) > 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5456d2c",
   "metadata": {},
   "source": [
    "# Melt the subgroup flags into one column so you can group by them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f44fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of binary subgroup columns\n",
    "subgroup_cols = ['frau1', 'nongerman', 'nongerman_male', 'nongerman_female']\n",
    "\n",
    "# Melt to long format: one row per (row, subgroup) where value == 1\n",
    "df_long = df.melt(\n",
    "    id_vars=['UniverseID', 'feature_set', 'model', 'is_ambiguous'], #'threshold_policy'\n",
    "    value_vars=subgroup_cols,\n",
    "    var_name='subgroup',\n",
    "    value_name='is_member'\n",
    ")\n",
    "\n",
    "# Filter to keep only the subgroup memberships (i.e., rows where the person is in that group)\n",
    "df_long = df_long[df_long['is_member'] == 1]\n",
    "\n",
    "# in subgroup column it says \"other 9%\", for what does it stand? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f452b",
   "metadata": {},
   "source": [
    "# Compute the fraction of ambiguous predictions per (universe, subgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e1fc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['UniverseID', 'feature_set', 'model', 'subgroup'] #'threshold_policy',\n",
    "fractions = df_long.groupby(group_cols)['is_ambiguous'].mean().reset_index()\n",
    "fractions.rename(columns={'is_ambiguous': 'ambiguity_fraction'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a67c1",
   "metadata": {},
   "source": [
    "# For each universe, compute the maximum pairwise difference in ambiguity fraction between subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c158d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute disparity per universe = max - min ambiguity_fraction across subgroups\n",
    "disparity_df = fractions.groupby(['feature_set', 'model'])['ambiguity_fraction']\\\n",
    "                        .agg(lambda x: x.max() - x.min())\\\n",
    "                        .reset_index(name='ambiguity_disparity')\n",
    "\n",
    "## add universe id \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cefae4",
   "metadata": {},
   "source": [
    "# fANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61602ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ConfigSpace import ConfigurationSpace, CategoricalHyperparameter\n",
    "from fanova import fANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6201a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ConfigSpace with categorical decision options\n",
    "cs = ConfigurationSpace()\n",
    "for col in ['feature_set', 'model', 'threshold_policy']:\n",
    "    choices = sorted(disparity_df[col].unique().tolist())\n",
    "    cs.add(CategoricalHyperparameter(col, choices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47736203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical values as integer codes\n",
    "#encoders = {\n",
    "#    col: {val: idx for idx, val in enumerate(sorted(disparity_df[col].unique()))}\n",
    "#    for col in ['feature_set', 'model', 'threshold_policy']\n",
    "#}\n",
    "#\n",
    "#X = np.vstack([\n",
    "#    disparity_df['feature_set'].map(encoders['feature_set']),\n",
    "#    disparity_df['model'].map(encoders['model']),\n",
    "#    disparity_df['threshold_policy'].map(encoders['threshold_policy']),\n",
    "#]).T\n",
    "#\n",
    "#Y = disparity_df['ambiguity_disparity'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7395085",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_order = [hp.name for hp in cs.values()]\n",
    "X = disparity_df[hp_order].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map categorical values to integers (same as before)\n",
    "for col in hp_order:\n",
    "    encoder = {val: i for i, val in enumerate(sorted(disparity_df[col].unique()))}\n",
    "    X[col] = X[col].map(encoder)\n",
    "\n",
    "X_array = X.to_numpy(dtype=float)  # ensure float dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1502d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = disparity_df['ambiguity_disparity'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e20044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fANOVA\n",
    "fanova = fANOVA(X_array, Y, config_space=cs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get individual importance scores\n",
    "importance = {\n",
    "    'feature_set': fanova.quantify_importance((0,))['individual importance'],\n",
    "    'model': fanova.quantify_importance((1,))['individual importance'],\n",
    "    'threshold_policy': fanova.quantify_importance((2,))['individual importance'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229813f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"fANOVA results (variance explained in ambiguity disparity):\")\n",
    "for key, val in importance.items():\n",
    "    print(f\"  {key}: {val * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0221b07d",
   "metadata": {},
   "source": [
    "# fANOVA v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "766027a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "if not hasattr(np, 'float'):\n",
    "    np.float = float  # Patch for fanova compatibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94a33d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build ConfigSpace and add hyperparameters\n",
    "from ConfigSpace import ConfigurationSpace, CategoricalHyperparameter\n",
    "\n",
    "cs = ConfigurationSpace()\n",
    "cs.add(\n",
    "    CategoricalHyperparameter(\"feature_set\", sorted(disparity_df[\"feature_set\"].unique())),\n",
    "    CategoricalHyperparameter(\"model\", sorted(disparity_df[\"model\"].unique())),\n",
    "    #CategoricalHyperparameter(\"threshold_policy\", sorted(disparity_df[\"threshold_policy\"].unique()))\n",
    ")\n",
    "\n",
    "# Step 2: Get correct hyperparameter order\n",
    "hp_order = [hp.name for hp in list(cs.values())]\n",
    "\n",
    "# Step 3: Encode categorical variables using consistent mapping\n",
    "X_df = disparity_df[hp_order].copy()\n",
    "for col in hp_order:\n",
    "    encoder = {val: i for i, val in enumerate(sorted(X_df[col].unique()))}\n",
    "    X_df[col] = X_df[col].map(encoder)\n",
    "X_df = X_df.astype(float)\n",
    "\n",
    "# Step 4: Now pass this labeled DataFrame directly to fANOVA\n",
    "from fanova import fANOVA\n",
    "\n",
    "Y = disparity_df[\"ambiguity_disparity\"].to_numpy()\n",
    "fanova = fANOVA(X_df, Y, config_space=cs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d098efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not compute importance for feature_set: 'SwigPyObject' object has no attribute 'mean'\n",
      "Could not compute importance for model: 'SwigPyObject' object has no attribute 'mean'\n",
      "fANOVA: Individual variance explained per decision factor (%):\n",
      "Empty DataFrame\n",
      "Columns: [individual importance]\n",
      "Index: []\n",
      "swig/python detected a memory leak of type 'rfr::util::weighted_running_statistics< double > *', no destructor found.\n",
      "swig/python detected a memory leak of type 'rfr::util::weighted_running_statistics< double > *', no destructor found.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract hyperparameters in correct order (no deprecated method)\n",
    "hp_list = list(cs.values())\n",
    "\n",
    "importance_scores = {}\n",
    "\n",
    "# Step 2: Loop through in order and extract individual importance scores\n",
    "for i, hp in enumerate(hp_list):\n",
    "    try:\n",
    "        result = fanova.quantify_importance((i,))\n",
    "        importance_scores[hp.name] = result[\"individual importance\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Could not compute importance for {hp.name}: {e}\")\n",
    "\n",
    "# Step 3: Format and display\n",
    "importance_df = pd.DataFrame.from_dict(\n",
    "    importance_scores, orient=\"index\", columns=[\"individual importance\"]\n",
    ")\n",
    "importance_df.sort_values(\"individual importance\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"fANOVA: Individual variance explained per decision factor (%):\")\n",
    "print((importance_df * 100).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07fe21ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var(Y): 5.778320607927732e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Var(Y):\", np.var(Y))\n",
    "# extremly small variance, so not much to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f4bb747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (6, 2)\n",
      "Unique values per column:\n",
      "feature_set    2\n",
      "model          3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X_df.shape)\n",
    "print(\"Unique values per column:\")\n",
    "print(X_df.nunique())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
