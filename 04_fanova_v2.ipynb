{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67561337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70fab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/all_universe_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Mark each prediction as ambiguous\n",
    "#df['is_ambiguous'] = df['pred_set'].apply(lambda labels: 1 if len(labels) > 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a795fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df['pred_set'] = df['pred_set'].apply(\n",
    "    lambda x: literal_eval(x) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e014e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_ambiguous'] = df['pred_set'].apply(lambda preds: 1 if len(preds) > 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e56170f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         pred_set  true_label  frau1  nongerman  nongerman_male  \\\n",
       "0            {0}           0      1        0.0               0   \n",
       "1            {0}           0      0        0.0               0   \n",
       "2            {0}           0      1        1.0               0   \n",
       "3            {0}           0      0        0.0               0   \n",
       "4            {0}           0      1        0.0               0   \n",
       "...          ...         ...    ...        ...             ...   \n",
       "1043791      {0}           0      0        0.0               0   \n",
       "1043792   {0, 1}           0      0        0.0               0   \n",
       "1043793      {0}           0      0        0.0               0   \n",
       "1043794      {0}           0      1        0.0               0   \n",
       "1043795      {0}           1      1        0.0               0   \n",
       "\n",
       "         nongerman_female   model        feature_set threshold_policy  \\\n",
       "0                       0  logreg     with_protected            top15   \n",
       "1                       0  logreg     with_protected            top15   \n",
       "2                       1  logreg     with_protected            top15   \n",
       "3                       0  logreg     with_protected            top15   \n",
       "4                       0  logreg     with_protected            top15   \n",
       "...                   ...     ...                ...              ...   \n",
       "1043791                 0      rf  without_protected            top30   \n",
       "1043792                 0      rf  without_protected            top30   \n",
       "1043793                 0      rf  without_protected            top30   \n",
       "1043794                 0      rf  without_protected            top30   \n",
       "1043795                 0      rf  without_protected            top30   \n",
       "\n",
       "         UniverseID  is_ambiguous  \n",
       "0                 1             0  \n",
       "1                 1             0  \n",
       "2                 1             0  \n",
       "3                 1             0  \n",
       "4                 1             0  \n",
       "...             ...           ...  \n",
       "1043791          12             0  \n",
       "1043792          12             1  \n",
       "1043793          12             0  \n",
       "1043794          12             0  \n",
       "1043795          12             0  \n",
       "\n",
       "[1043796 rows x 11 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ef13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compute the fraction of ambiguous predictions for each combination of (universe decisions + subgroup)\n",
    "#group_cols = ['feature_set', 'model', 'threshold_policy', 'gender', 'nationality']\n",
    "#fractions = df.groupby(group_cols)['is_ambiguous'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c4ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `fractions` now contains one row per (feature_set, model, threshold_policy, gender, nationality) \n",
    "# with the mean of `is_ambiguous`, which is the fraction of predictions that are ambiguous in that subgroup.\n",
    "#print(fractions.head())  # For debugging: view the first few rows of fraction results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5456d2c",
   "metadata": {},
   "source": [
    "# Melt the subgroup flags into one column so you can group by them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f44fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of binary subgroup columns\n",
    "subgroup_cols = ['frau1', 'nongerman', 'nongerman_male', 'nongerman_female']\n",
    "\n",
    "# Melt to long format: one row per (row, subgroup) where value == 1\n",
    "df_long = df.melt(\n",
    "    id_vars=['feature_set', 'model', 'threshold_policy', 'is_ambiguous'],\n",
    "    value_vars=subgroup_cols,\n",
    "    var_name='subgroup',\n",
    "    value_name='is_member'\n",
    ")\n",
    "\n",
    "# Filter to keep only the subgroup memberships (i.e., rows where the person is in that group)\n",
    "df_long = df_long[df_long['is_member'] == 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f452b",
   "metadata": {},
   "source": [
    "# Compute the fraction of ambiguous predictions per (universe, subgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e1fc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['feature_set', 'model', 'threshold_policy', 'subgroup']\n",
    "fractions = df_long.groupby(group_cols)['is_ambiguous'].mean().reset_index()\n",
    "fractions.rename(columns={'is_ambiguous': 'ambiguity_fraction'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a67c1",
   "metadata": {},
   "source": [
    "# For each universe, compute the maximum pairwise difference in ambiguity fraction between subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c158d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute disparity per universe = max - min ambiguity_fraction across subgroups\n",
    "disparity_df = fractions.groupby(['feature_set', 'model', 'threshold_policy'])['ambiguity_fraction']\\\n",
    "                        .agg(lambda x: x.max() - x.min())\\\n",
    "                        .reset_index(name='ambiguity_disparity')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
