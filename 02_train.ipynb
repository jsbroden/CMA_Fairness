{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7bebcf4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08327b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate # GroupKFold, GridSearchCV,\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from joblib import dump, load\n",
    "\n",
    "from utils import (\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    "    #get_topk_scorers,\n",
    "    summarize_by_predset,\n",
    "    #compute_group_proportions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298f2b2",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa524e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f = pd.read_csv(\"./output/X_train_f.csv\") # 2010 - 2014, w. protected attributes\n",
    "X_train_s = pd.read_csv(\"./output/X_train_s.csv\") # 2010 - 2014, w/o protected attributes\n",
    "y_train = pd.read_csv(\"./output/y_train.csv\").iloc[:,0]\n",
    "\n",
    "X_test_f = pd.read_csv(\"./output/X_test_f.csv\")\n",
    "X_test_s = pd.read_csv(\"./output/X_test_s.csv\")\n",
    "y_test = pd.read_csv(\"./output/y_test.csv\").iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d403690f",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "283cf1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "(None, None)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "70e0a9b0-d6cd-4334-932c-903d46ae10e9",
       "rows": [
        [
         "('ft_tot_dur_byage', 'ft_tot_dur')",
         "0.9541610192159021"
        ],
        [
         "('ft_tot_dur', 'ft_tot_dur_byage')",
         "0.9541610192159021"
        ],
        [
         "('maxbula.Missing.', 'lastjob_pt99999')",
         "0.9545244880550865"
        ],
        [
         "('lastjob_pt99999', 'maxbula.Missing.')",
         "0.9545244880550865"
        ],
        [
         "('seeking1_tot_dur_byage', 'seeking1_tot_dur')",
         "0.9554199560118939"
        ],
        [
         "('seeking1_tot_dur', 'seeking1_tot_dur_byage')",
         "0.9554199560118939"
        ],
        [
         "('lastjob_none', 'maxbula.Missing.')",
         "0.9611197122038286"
        ],
        [
         "('maxbula.Missing.', 'lastjob_none')",
         "0.9611197122038286"
        ],
        [
         "('lastjob_type99999', 'maxbula.Missing.')",
         "0.9611197122038286"
        ],
        [
         "('maxbula.Missing.', 'tsince_lm_contact_cat5')",
         "0.9611197122038286"
        ],
        [
         "('tsince_lm_contact_cat5', 'maxbula.Missing.')",
         "0.9611197122038286"
        ],
        [
         "('maxbula.Missing.', 'lastjob_type99999')",
         "0.9611197122038286"
        ],
        [
         "('maxbula.Missing.', 'lastjob_parallel99999')",
         "0.9611197122038287"
        ],
        [
         "('lastjob_parallel99999', 'maxbula.Missing.')",
         "0.9611197122038287"
        ],
        [
         "('emp1_total_dur', 'emp1_total_dur_byage')",
         "0.9634949129039041"
        ],
        [
         "('emp1_total_dur_byage', 'emp1_total_dur')",
         "0.9634949129039041"
        ],
        [
         "('secjob_tot_dur', 'secjob_tot_dur_byage')",
         "0.9658842568532805"
        ],
        [
         "('secjob_tot_dur_byage', 'secjob_tot_dur')",
         "0.9658842568532805"
        ],
        [
         "('LEH_tot_dur_byage', 'LEH_tot_dur')",
         "0.9773088010525277"
        ],
        [
         "('LEH_tot_dur', 'LEH_tot_dur_byage')",
         "0.9773088010525277"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 20
       }
      },
      "text/plain": [
       "ft_tot_dur_byage        ft_tot_dur                0.954161\n",
       "ft_tot_dur              ft_tot_dur_byage          0.954161\n",
       "maxbula.Missing.        lastjob_pt99999           0.954524\n",
       "lastjob_pt99999         maxbula.Missing.          0.954524\n",
       "seeking1_tot_dur_byage  seeking1_tot_dur          0.955420\n",
       "seeking1_tot_dur        seeking1_tot_dur_byage    0.955420\n",
       "lastjob_none            maxbula.Missing.          0.961120\n",
       "maxbula.Missing.        lastjob_none              0.961120\n",
       "lastjob_type99999       maxbula.Missing.          0.961120\n",
       "maxbula.Missing.        tsince_lm_contact_cat5    0.961120\n",
       "tsince_lm_contact_cat5  maxbula.Missing.          0.961120\n",
       "maxbula.Missing.        lastjob_type99999         0.961120\n",
       "                        lastjob_parallel99999     0.961120\n",
       "lastjob_parallel99999   maxbula.Missing.          0.961120\n",
       "emp1_total_dur          emp1_total_dur_byage      0.963495\n",
       "emp1_total_dur_byage    emp1_total_dur            0.963495\n",
       "secjob_tot_dur          secjob_tot_dur_byage      0.965884\n",
       "secjob_tot_dur_byage    secjob_tot_dur            0.965884\n",
       "LEH_tot_dur_byage       LEH_tot_dur               0.977309\n",
       "LEH_tot_dur             LEH_tot_dur_byage         0.977309\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computes the absolute value of the correlation matrix for the training features with protected attributes\n",
    "corrM = X_train_f.corr().abs() # Corr matrix of X\n",
    "corrM = corrM.unstack() # flatten\n",
    "corrMo = corrM.sort_values(kind = \"quicksort\") # sort correlations\n",
    "corrMo[corrMo < 1].tail(20) # Filters out the self-correlations (which equal 1) and prints the last 20 entries (lowest correlations)\n",
    "\n",
    "# to spot which features (including protected‐attribute proxies) are most strongly correlated, so I can \n",
    "# watch out for multicollinearity or fairness-related leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6d8d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(4) # Create splits by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4261ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 4997 4998 4999] TEST: [5000 5001 5002 ... 9997 9998 9999]\n",
      "TRAIN: [   0    1    2 ... 9997 9998 9999] TEST: [10000 10001 10002 ... 14997 14998 14999]\n",
      "TRAIN: [    0     1     2 ... 14997 14998 14999] TEST: [15000 15001 15002 ... 19997 19998 19999]\n",
      "TRAIN: [    0     1     2 ... 19997 19998 19999] TEST: [20000 20001 20002 ... 24997 24998 24999]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in tscv.split(X_train_f):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ebd83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_25(y_true, y_score, **kwargs):\n",
    "    return precision_at_k(y_true, y_score, 0.25)\n",
    "def precision_at_10(y_true, y_score, **kwargs):\n",
    "    return precision_at_k(y_true, y_score, 0.10)\n",
    "def recall_at_25(y_true, y_score, **kwargs):\n",
    "    return recall_at_k(y_true, y_score, 0.25)\n",
    "def recall_at_10(y_true, y_score, **kwargs):\n",
    "    return recall_at_k(y_true, y_score, 0.10)\n",
    "\n",
    "custom_precision25 = make_scorer(precision_at_25, needs_proba=True) # Precision at top 25%\n",
    "custom_precision10 = make_scorer(precision_at_10, needs_proba=True) # Precision at top 10%\n",
    "custom_recall25 = make_scorer(recall_at_25, needs_proba = True) # Recall at top 25%\n",
    "custom_recall10 = make_scorer(recall_at_10, needs_proba = True) # Recall at top 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed737cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = {'log_loss': 'neg_log_loss',\n",
    "         'auc': 'roc_auc',\n",
    "         'precision': 'precision', # uses default model threshold of 0.5\n",
    "         'recall': 'recall',\n",
    "         'precision_at_k25': custom_precision25, # uses custom threshold \n",
    "         'recall_at_k25': custom_recall25,\n",
    "         'precision_at_k10': custom_precision10,\n",
    "         'recall_at_k10': custom_recall10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea6157e",
   "metadata": {},
   "source": [
    "## 01 Logit Regression (w. protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm1 = LogisticRegression(penalty = None, solver = 'lbfgs', max_iter = 1000)\n",
    "glm1.fit(X_train_f, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "glmcv1 = cross_validate(estimator = glm1, \n",
    "                       X = X_train_f,\n",
    "                       y = y_train,\n",
    "                       cv = tscv,\n",
    "                       n_jobs = -1, # use all available cores\n",
    "                       scoring = score)\n",
    "\n",
    "# !!! recall always 1.0, check if this is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs1 = pd.DataFrame(X_train_f.columns, columns = ['var'])\n",
    "coefs1['coef'] = pd.DataFrame(glm1.coef_).transpose()\n",
    "\n",
    "# Build a DataFrame of feature names + their learned coefficients, to inspect which variables \n",
    "# (including protected attrs) the model weights most heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(glm1, './models/glm1.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9509612",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "k75 = 0.75 # Top 75% \n",
    "k25 = 0.25 # Top 25% \n",
    "k10 = 0.1 # Top 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e6b68cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glm1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m glm1_p = \u001b[43mglm1\u001b[49m.predict_proba(X_test_f)[:,\u001b[32m1\u001b[39m] \u001b[38;5;66;03m# glm1\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Generate the predicted probability of the positive class for each test sample\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'glm1' is not defined"
     ]
    }
   ],
   "source": [
    "glm1_p = glm1.predict_proba(X_test_f)[:,1] # glm1\n",
    "\n",
    "# Generate the predicted probability of the positive class for each test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da52b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold75 = np.sort(glm1_p)[::-1][int(k75*len(glm1_p))]\n",
    "threshold25 = np.sort(glm1_p)[::-1][int(k25*len(glm1_p))]\n",
    "threshold10 = np.sort(glm1_p)[::-1][int(k10*len(glm1_p))] # threshold10 is the score above which only the top 10% of test samples lie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm1_c1 = glm1_p.copy()\n",
    "glm1_c1[glm1_c1 < threshold10] = 0\n",
    "glm1_c1[glm1_c1 >= threshold10] = 1\n",
    "\n",
    "# Create a binary classification vector where only the top 10% by predicted probability are labeled “1”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c693db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm1_c2 = glm1_p.copy()\n",
    "glm1_c2[glm1_c2 < threshold25] = 0\n",
    "glm1_c2[glm1_c2 >= threshold25] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm1_c3 = glm1_p.copy()\n",
    "glm1_c3[(glm1_c3 <= threshold75) | (glm1_c3 >= threshold25)] = 0\n",
    "glm1_c3[(glm1_c3 > threshold75) & (glm1_c3 < threshold25)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d561c",
   "metadata": {},
   "source": [
    "## Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce6795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c80d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for preds, label in zip(\n",
    "    [glm1_c1, glm1_c2, glm1_c3],\n",
    "    [\"Top 10%\", \"Top 25%\", \"Middle 25–75%\"]\n",
    "):\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1  = f1_score(y_test, preds)\n",
    "    print(f\"{label:15s} → Accuracy: {acc:.3f},  F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802e105f",
   "metadata": {},
   "source": [
    "## Combine and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Build a single DataFrame side by side with:\n",
    "      - The true labels (‘y_test’)\n",
    "      - The raw predicted probabilities (‘glm1_p’)\n",
    "      - Each binary decision vector at different cutoffs (‘glm1_c1’, ‘glm1_c2’, ‘glm1_c3’).\n",
    "'''\n",
    "\n",
    "preds_test = pd.concat([pd.DataFrame(np.array(y_test), columns = ['y_test']),\n",
    "                         pd.DataFrame(glm1_p, columns = ['glm1_p']),\n",
    "                         pd.DataFrame(glm1_c1, columns = ['glm1_c1']),\n",
    "                         pd.DataFrame(glm1_c2, columns = ['glm1_c2']),\n",
    "                         pd.DataFrame(glm1_c3, columns = ['glm1_c3'])],\n",
    "                        axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caba314",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test.to_csv('./output/preds_test.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cma_f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
